<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title>Hello World</title>
    <url>/2022/08/18/hello-world/</url>
    <content><![CDATA[<p>Welcome to <a href="https://hexo.io/">Hexo</a>! This is your very
first post. Check <a href="https://hexo.io/docs/">documentation</a> for
more info. If you get any problems when using Hexo, you can find the
answer in <a
href="https://hexo.io/docs/troubleshooting.html">troubleshooting</a> or
you can ask me on <a
href="https://github.com/hexojs/hexo/issues">GitHub</a>.</p>
<h2 id="quick-start">Quick Start</h2>
<h3 id="create-a-new-post">Create a new post</h3>
<figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash">$ hexo new <span class="hljs-string">&quot;My New Post&quot;</span><br></code></pre></td></tr></table></figure>
<p>More info: <a
href="https://hexo.io/docs/writing.html">Writing</a></p>
<h3 id="run-server">Run server</h3>
<figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash">$ hexo server<br></code></pre></td></tr></table></figure>
<p>More info: <a href="https://hexo.io/docs/server.html">Server</a></p>
<h3 id="generate-static-files">Generate static files</h3>
<figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash">$ hexo generate<br></code></pre></td></tr></table></figure>
<p>More info: <a
href="https://hexo.io/docs/generating.html">Generating</a></p>
<h3 id="deploy-to-remote-sites">Deploy to remote sites</h3>
<figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash">$ hexo deploy<br></code></pre></td></tr></table></figure>
<p>More info: <a
href="https://hexo.io/docs/one-command-deployment.html">Deployment</a></p>
]]></content>
  </entry>
  <entry>
    <title>放学后</title>
    <url>/2022/08/27/%E6%94%BE%E5%AD%A6%E5%90%8E/</url>
    <content><![CDATA[<style>
  .markdown-body {
    font-family: Microsoft JhengHei, SimHei;
    font-size: 16px;
  }
</style>
<h1 align="center">
《放学后》
</h1>
<p>1.一口气看完了东野圭吾的《放学后》，作为一篇的悬疑推理小说，不论是情节的组织、细节的设计铺垫方面都是很不错的，也有东野圭吾一贯擅长的反转再反转，结局出人意料，回味前文的细节又觉得在情理之中，读完之后觉得深感震撼。</p>
<p>2.主角前岛是清华女中的一位数学老师，同时担任射箭社的指导老师，他不擅长上课，不擅长和学生互动，只是本分地完成自身的教学工作，被学生们叫做“机器”。就是这样一个不太和他人有交集以及过节的人，一次又一次险些遭人陷害，从天而降的花盆、泳池中的插电板、被人推向飞驰而过的列车……一次又一次险些丧命。这让他很是小心，急迫想要找出陷害他的人。而在他找到答案之前，同为数学老师的村桥老师在更衣室中被人杀害，警方介入调查。一波未平一波又起，在化装表演时，扮成小丑的竹井老师因为喝下道具酒瓶中的液体当场倒地身亡。</p>
<p>3.一切都是因为射箭社的惠子和惠美遭到了村桥和竹井的“视线强暴”，于是萌生了杀人的想法。她们用箭将男更衣室的门抵住，并且在男更衣室与女更衣室间隔的墙上留下痕迹，伪造了一幅凶手从女更衣室逃走的假象，误导警方断案。而在村桥的衣服中也发现了麻生老师的不雅照片，这是村桥老师逼迫麻生老师和他继续维持关系的砝码，后来却成了惠子和惠美威胁麻生协助杀害竹井老师的手段。那些让前岛一次又一次险些丧命的事件原来是她们伪造出来的假象，让警方误认为凶手想杀害的是前岛而不是竹井。</p>
<p>4.故事最后，前岛和妻子通过话后准备回家，却被一个陌生男子用刀捅死，故事戛然而止。委婉地叙述了妻子杀害前岛这一事实，让人大受震撼，但是转念回想前文，前岛和妻子意外有了孩子，前岛执意打掉了孩子，妻子因此也落寞了许久。这样结尾又在情理之中，妻子积怨已久，最终动手杀害了前岛。</p>
<p>5.一些书摘：</p>
<blockquote>
<p>成年人的案件倒不见得会那么复杂。报纸社会新闻版总有各种闹得沸沸扬扬的事件，几乎都能用色、欲、财这三要素来概括</p>
</blockquote>
<blockquote>
<p>但高中女生，就不能拿着几点来套了</p>
<p>对她们来说，最重要的应该是美丽、纯粹、真实的东西，比如友情、爱情，也可能是自己的身体或容貌。很多时候，更抽象的回忆或梦想对她们来说也很重要。反过来说，她们最憎恨企图破坏或从她们手中夺走这些重要东西的人</p>
</blockquote>
<p>6.处于青春期的孩子，自尊心是高于一切的，而成年人们最容易忽视的往往就是自尊心。有意无意间践踏了她们的自尊心却不自知，最终酿成悲剧。小说中还有一位女生叫阳子，她没有直接参与到几次谋杀案中。她母亲很早离世，父亲是位企业家，也无暇顾及女儿。阳子曾邀请前岛一同旅行，前岛最终是放了格子，阳子一人在车站苦苦等待了几个小时。在此之后，阳子也走向了堕落，同小混混飙车麻痹自己。没有人生来就是坏孩子，她们的成长也需要作为成年人的家长、老师的呵护。</p>
<p>7.主角前岛的死也是一出悲剧，忽视了妻子的感受，让负面的情绪在不断积攒，最终上演了悲剧。</p>
]]></content>
      <categories>
        <category>阅读</category>
      </categories>
      <tags>
        <tag>阅读</tag>
      </tags>
  </entry>
  <entry>
    <title>白夜行</title>
    <url>/2022/09/04/%E7%99%BD%E5%A4%9C%E8%A1%8C/</url>
    <content><![CDATA[<style>
  .markdown-body {
    font-family: Microsoft JhengHei, SimHei;
    font-size: 16px;
  }
</style>
<h1 align="center">
《白夜行》
</h1>
<ol type="1">
<li><p>雪穗，生活在一个贫苦的单亲家庭，在母亲的策划下，即使还是个上小学的幼女却被迫出卖身体。</p></li>
<li><p>亮司，多次目睹母亲和雇佣的店员偷腥，甚至发现了父亲玷污自己的好朋友雪穗。</p></li>
<li><p>两人都有着极其不幸的童年，他们一同杀害了亮司的父亲，也间接谋害了雪穗的母亲，从此，雪穗投靠了亲戚步步向上走，而亮司也离开了母亲，一直生活在阴暗的世界里，帮助雪穗。</p></li>
<li><p>他们谋划了一起又一起犯罪事件，所有影响到雪穗人生的人物无一例外都遭到了他们的毒手。</p></li>
<li><p>最终他们都变成了自己最讨厌的模样：在雪穗的谋划下，自己女儿遭到了强暴，亮司正是强暴幼女的凶手。</p></li>
<li><p>不幸的童年造成了层出不穷的悲剧，但这并不是他们作恶多端的借口，他们不值得同情，那些他们手下的受害者又由谁去同情</p></li>
<li><blockquote>
<p>"我的人生就像在白夜里走路"</p>
</blockquote></li>
<li><blockquote>
<p>"一天当中，有太阳升起的时候，也有下沉的时候。人生也一样，有白天和黑夜，只是不会像真正的太阳那样，有定时的日出和日落。看个人，有些人一辈子都活在太阳的照耀下，也有些人不得不一直活在漆黑的深夜里。人害怕的，就是本来一直存在的太阳落下不再升起，也就是非常害怕原本照在身上的光芒消失"</p>
</blockquote></li>
</ol>
]]></content>
      <categories>
        <category>阅读</category>
      </categories>
      <tags>
        <tag>阅读</tag>
      </tags>
  </entry>
  <entry>
    <title>贝叶斯决策理论</title>
    <url>/2022/09/13/%E8%B4%9D%E5%8F%B6%E6%96%AF%E5%86%B3%E7%AD%96%E7%90%86%E8%AE%BA/</url>
    <content><![CDATA[<style>
  .markdown-body {
    font-family: Microsoft JhengHei, SimHei;
    font-size: 16px;
  }
</style>
<h1 align="center">
贝叶斯决策理论
</h1>
<h2 id="basics-of-probability概率论基础知识">1. Basics of
Probability(概率论基础知识)</h2>
<ul>
<li>$ A独立于B时,P(A|B) = P(A) $</li>
<li>$ P(A|B)= $</li>
<li>$ A、B相互独立 当且仅当 P(A,B)=P(A)P(B) $</li>
</ul>
<h2 id="bayes-theorem贝叶斯理论">2. Bayes' Theorem(贝叶斯理论)</h2>
<p><span class="math display">\[
P(\omega|x) = \frac{p(x|\omega)p(\omega)}{p(x)}\\
Posterior = (Likelihood \times Prior) / Evidence\\
p(x) = \sum_{i=1}^{k}p(x|\omega_i)p(\omega_i)
\]</span></p>
<ul>
<li><span class="math inline">\(P(\omega|x)\)</span> :
posterior,后验概率,<font color=red>已发生事件</font>出于某种因素引发的概率</li>
<li><span class="math inline">\(p(x|\omega)\)</span> :
likelihood,似然,数据符合<font color=red>某种分布</font>的概率大小</li>
<li><span class="math inline">\(p(\omega)\)</span> :
prior,先验概率,<font color=red>未发生事件</font>依据以往经验得知的概率</li>
<li><span class="math inline">\(p(x)\)</span> :
evidence,往往作为一个<font color=red>常数</font></li>
</ul>
<blockquote>
<p>其中 x为样本</p>
</blockquote>
<h2 id="optimal-bayes-decision-rule最优贝叶斯决策规则">3. Optimal Bayes
Decision Rule(最优贝叶斯决策规则)</h2>
<p><strong>一个物体选择后验概率大的作为其分类可以最小化决策误差</strong></p>
<p><span class="math inline">\(P(\omega_1|x) &gt;
P(\omega_2|x)\)</span>时认为它是<span
class="math inline">\(\omega_1\)</span></p>
<p><span class="math inline">\(P(\omega_1|x) &lt;
P(\omega_2|x)\)</span>时认为它是<span
class="math inline">\(\omega_2\)</span></p>
<blockquote>
<p>同理或者选择风险R小的</p>
</blockquote>
<p>特殊情况：</p>
<ul>
<li><p><span class="math inline">\(p(\omega_1)=p(\omega_2)\)</span> :
<span
class="math inline">\(p(x|\omega_1)&gt;p(x|\omega_2)\)</span>时认为是<span
class="math inline">\({\omega}_1\)</span></p>
<blockquote>
<p>最大似然决策法</p>
<p>本质上和一般情况没有区别，只是先验概率相同可以同时约去，不加入比较，直接比较似然度</p>
</blockquote></li>
<li><p><span class="math inline">\(p(x|\omega_1)=p(x|\omega_2)\)</span>
: <span
class="math inline">\(p(\omega_1)&gt;p(\omega_2)\)</span>时认为是<span
class="math inline">\({\omega}_1\)</span></p>
<blockquote>
<p>同上</p>
</blockquote></li>
</ul>
<h2 id="bayes-risk">4. Bayes Risk</h2>
<p>Conditional Risk <span class="math display">\[
R(\alpha_i|x)=\sum_{j=1}^{c}\lambda(\alpha_i|\omega_j)P(\omega_j|x)
\]</span></p>
<blockquote>
<p><span class="math inline">\(\alpha\)</span> 代表 采取的行为</p>
</blockquote>
<p>Overall Risk <span class="math display">\[
R = \int R(\alpha_i|x)p(x)dx
\]</span> Bayes Risk</p>
<ul>
<li>风险最小时的R</li>
</ul>
<h2 id="example-1two-category-classification">Example 1：Two-category
classification</h2>
<p>给定： <span class="math display">\[
\alpha_1 = deciding \space \omega_1 \\
\alpha_2 = deciding \space \omega_2 \\
\lambda_{ij} = \lambda(\alpha_i | \omega_j)
\]</span> 于是条件风险： <span class="math display">\[
R(\alpha_1 | x) = \lambda_{11}P(\omega_1 | x) + \lambda_{12}P(\omega_2 |
x) \\
R(\alpha_2 | x) = \lambda_{21}P(\omega_1 | x) + \lambda_{22}P(\omega_2 |
x)
\]</span> 如何找到贝叶斯风险？？？</p>
<p>认为是<span class="math inline">\({\omega}_1\)</span>当 <span
class="math display">\[
R(\alpha_1 | x) &lt; R(\alpha_2 | x)
\]</span> 展开并移项化简得到(认为是<span
class="math inline">\({\omega}_1\)</span>的情况) <span
class="math display">\[
\frac{P(x|\omega_1)}{P(x|\omega_2)} &gt;
\frac{\lambda_{12}-\lambda_{22}}{\lambda_{21}-\lambda_{11}} \times
\frac{P(\omega_2)}{P(\omega_1)}
\]</span></p>
<h2 id="example-2-minimum-error-rate-classification">Example 2:
Minimum-Error-Rate Classification</h2>
<p>给定</p>
<ul>
<li>对于动作<span
class="math inline">\(\alpha_i\)</span>和事实上的类别<span
class="math inline">\(\omega_j\)</span> ,如果<span
class="math inline">\(i=j\)</span>就是正确的，否则错误</li>
</ul>
<p>找到最小损失的分类</p>
<p>写出损失函数(Zero-one loss function): <span class="math display">\[
\lambda(\alpha_i | \omega_j) =
\begin{cases}
0&amp; \text{i = j}\\
1&amp; \text{i} \neq \text{j}
\end{cases}
\]</span> 于是可以计算条件风险 <span class="math display">\[
R(\alpha_i|x) = \sum_{j=1}^{c} \lambda(\alpha_i|\omega_j)P(\omega_j | x)
\\
= \sum_{j{\neq}i} P(\omega_j | x) = 1-P(\omega_i | x)
\]</span>
需要风险最小化，由上述式子可知需要后验概率最大化，选择后验概率最大的即可</p>
]]></content>
      <categories>
        <category>机器学习</category>
      </categories>
      <tags>
        <tag>机器学习</tag>
      </tags>
  </entry>
</search>
