<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title>Classes of differentiable functions</title>
    <url>/2022/10/06/Classes-of-differentiable-functions/</url>
    <content><![CDATA[<style> 
    .markdown-body {
      font-family: Microsoft JhengHei, SimHei;
      font-size: 16px;
    }
</style>
<h1 align="center">
Classes of differentiable functions
</h1>
<h2 id="define-class-of-functions">1.Define class of functions</h2>
<p><span class="math inline">\(Q\)</span> is subset of <span class="math inline">\(R^n\)</span> , we denote <span class="math inline">\(C^{k,p}_L(Q)\)</span> the class of the
functions</p>
<p>properties:</p>
<ul>
<li><p>any <span class="math inline">\(f \in C^{k,p}_L(Q)\)</span> is
<font color="orange"><span class="math inline">\(k\)</span> times
continuesly differentiable</font> on <span class="math inline">\(Q\)</span>.</p></li>
<li><p>Its <span class="math inline">\(p\)</span>th derivative is
<font color="orange">Lipschitz colltinuous</font> on <span class="math inline">\(Q\)</span> with the constant <span class="math inline">\(L\)</span>: <span class="math display">\[
||f^{(p)}(x) - f^{(p)}(y)|| \le L||x-y||
\]</span></p></li>
<li><p>if <span class="math inline">\(f_1 \in C^{k,p}_{L_1}(Q)\)</span>
, <span class="math inline">\(f_2 \in C^{k,p}_{L_2}(Q)\)</span> and
<span class="math inline">\(\alpha,\beta \in R^1\)</span>, then for
<span class="math display">\[
\textcolor{orange}{L_3 = |\alpha|L_1 + |\beta|L_2}
\]</span> we have <span class="math inline">\(\alpha f_1 + \beta f_2 \in
C^{k,p}_{L_3}(Q)\)</span></p></li>
</ul>
<p>Most important class of functions is <span class="math inline">\(C^{1,1}_L(R^n)\)</span>, which implies that <span class="math display">\[
||f&#39;(x) - f&#39;(y)|| \le L||x-y|| \tag{1.2.3}
\]</span></p>
<h2 id="lemma-1.2.2">2.LEMMA 1.2.2</h2>
<p><span class="math inline">\(\textcolor{orange}{LEMMA \space
1.2.2}\)</span> Function <span class="math inline">\(f(x)\)</span>
belongs to <span class="math inline">\(C^{2,1}_L(R^n) \subset
C^{1,1}_L(R^n)\)</span> if and only if <span class="math display">\[
||f^{&#39;&#39;}(x)|| \le L, \space \space \space \forall x \in R^{n}
\tag{1.2.4}
\]</span></p>
<p>Proof.</p>
<p><span class="math inline">\(\Leftarrow\)</span>:</p>
<p>for any <span class="math inline">\(x,y \in R^n\)</span> we have
<span class="math display">\[
\begin{aligned}
f&#39;(y) &amp;= f&#39;(x) + f&#39;(y) - f&#39;(x) \\
      &amp;= f&#39;(x) + f&#39;(x + (y - x)) - f&#39;(x) \\
      &amp;= f&#39;(x) + \int^{1}_{0}f&#39;&#39;(x +
\tau(y-x))(y-x)d\tau \\
      &amp;= f&#39;(x) + (\int^{1}_{0}f&#39;&#39;(x +
\tau(y-x))d\tau)(y-x)
\end{aligned}
\]</span> therefore <span class="math display">\[
\begin{aligned}
||f&#39;(y) - f&#39;(x)|| &amp;= ||(\int^{1}_{0}f&#39;&#39;(x +
\tau(y-x))d\tau)\cdot(y-x)|| \\
&amp;\le ||(\int^{1}_{0}f&#39;&#39;(x + \tau(y-x))d\tau)||\cdot||(y-x)||
\\
&amp;\le \int^1_0||f&#39;&#39;(x+\tau(y-x))||d\tau \cdot ||y-x|| \\
&amp;\le L||y-x|| \space \space (apply \space 1.2.4)
\end{aligned}
\]</span></p>
<p><span class="math inline">\(\Rightarrow\)</span>:</p>
<p>for any <span class="math inline">\(s \in R^n\)</span> , <span class="math inline">\(\alpha &gt; 0\)</span>: <span class="math display">\[
||(\int_0^{\alpha}f&#39;&#39;(x + \tau s)d\tau) \cdot
s||=||f&#39;(x+\alpha s) - f&#39;(x)|| \le L||\alpha s|| = \alpha L||s||
\]</span> dividing by <span class="math inline">\(\alpha\)</span> and
let <span class="math inline">\(\alpha \rightarrow 0\)</span>, then
<span class="math display">\[
||f&#39;&#39;(x)|| \le L
\]</span></p>
<h2 id="lemma-1.2.3">3.LEMMA 1.2.3</h2>
<p><span class="math inline">\(\textcolor{orange}{LEMMA \space
1.2.3}\)</span> Let <span class="math inline">\(f \in
C^{1,1}_L(R^n)\)</span>. Then for any <span class="math inline">\(x,y\)</span> from <span class="math inline">\(R^n\)</span> we have <span class="math display">\[
|f(y)-f(x)-\langle f&#39;(x),y-x \rangle| \le \frac{L}{2}||y-x||^2
\tag{1.2.5}
\]</span></p>
<p>Proof.</p>
<p>For all <span class="math inline">\(x,y \in R^n\)</span> we have
<span class="math display">\[
\begin {aligned}
f(y) &amp;= f(x) + \int^{1}_{0}f&#39;(x + \tau(y-x))(y-x)d\tau \\
     &amp;= f(x) + \langle f&#39;(x),y-x \rangle +
\int^{1}_{0}f&#39;\langle x + \tau(y-x))-f&#39;(x),y-x\rangle d\tau
\end{aligned}
\]</span> therefore <span class="math display">\[
\begin{aligned}
|f(y)-f(x)-\langle f&#39;(x),y-x \rangle| &amp;=
|\int^{1}_{0}f&#39;\langle x + \tau(y-x))-f&#39;(x),y-x\rangle d\tau |
\\
&amp; \le \int^{1}_{0}|f&#39;\langle x +
\tau(y-x))-f&#39;(x),y-x\rangle| d\tau \\
&amp; \le \int^{1}_{0} || f&#39;( x +
\tau(y-x))-f&#39;(x))||\cdot||y-x|| d\tau \\
&amp; \le \int_0^1 \tau L ||y-x||^2 d\tau =\frac{L}{2}||y-x||^2
\end{aligned}
\]</span></p>
<h2 id="lemma-1.2.4">4.LEMMA 1.2.4</h2>
<p>Similarly we have</p>
<p><span class="math inline">\(\textcolor{orange}{LEMMA \space
1.2.4}\)</span> Let <span class="math inline">\(f \in
C^{2,2}_L(R^n)\)</span>. Then for any <span class="math inline">\(x,y\)</span> from <span class="math inline">\(R^n\)</span> we have <span class="math display">\[
||f&#39;(y)-f&#39;(x)-f&#39;&#39;(x)(y-x)|| \le \frac{M}{2}||y-x||^2
\]</span></p>
<p><span class="math display">\[
|f(y)-f(x)-\langle f&#39;(x),y-x\rangle -\frac{1}{2} \langle
f&#39;&#39;(x)(y-x),y-x \rangle| \le \frac{M}{6} ||y-x||^3
\]</span></p>
<h2 id="corollary-1.2.2">5.COROLLARY 1.2.2</h2>
<p><span class="math inline">\(\textcolor{orange}{COROLLARY \space
1.2.2}\)</span> Let <span class="math inline">\(f \in
C^{2,2}_M(R^n)\)</span> <span class="math display">\[
f&#39;&#39;(x)-M||y-x||I_n \preceq f&#39;&#39;(y) \preceq f&#39;&#39;(x)
+ M||y-x||I_n
\]</span></p>
]]></content>
      <categories>
        <category>凸优化</category>
      </categories>
      <tags>
        <tag>凸优化</tag>
      </tags>
  </entry>
  <entry>
    <title>Complexity bounds for global optimization</title>
    <url>/2022/09/22/Complexity-bounds-for-global-optimization/</url>
    <content><![CDATA[<style> 
    .markdown-body {
      font-family: Microsoft JhengHei, SimHei;
      font-size: 16px;
    }
</style>
<h1 align="center">
Complexity bounds for global optimization
</h1>
<h2 id="提出问题">1.提出问题</h2>
<p>一个约束最小化问题： <span class="math display">\[
\underset{x \in B_n}{min} f(x)
\]</span> 其中： <span class="math display">\[
B_n = \{ x \in R^n | 0 \le x^{(i)} \le1,i=1 ... n \}
\]</span> <span class="math inline">\(x\)</span>为<span class="math inline">\(n\)</span>维向量，<span class="math inline">\(x^{(i)}\)</span>为<span class="math inline">\(x\)</span>向量中的每一个分量</p>
<p>给出以下记号： <span class="math display">\[
||x||_{\infty} = \underset{1 \le i \le n}{max}|x^{(i)}|
\]</span></p>
<h2 id="利普希茨连续lipschitz-continuity">2.<strong>利普希茨连续</strong>(Lipschitz
continuity)</h2>
<p>一个函数是利普希茨连续的时有 <span class="math display">\[
|f(x)-f(y)| \le L ||x-y||_{\infty} \space \space \space \space \space
\space \space \space \forall x,y \in B_n
\]</span> 其中<span class="math inline">\(L\)</span>为利普希茨常数(Lipschitz constant)</p>
<h2 id="均格法uniform-grid-method解决">3.均格法(uniform grid
method)解决</h2>
<p><span class="math display">\[
Method \space \space  \mathscr{G}(p)
\]</span></p>
<ul>
<li>构造<span class="math inline">\((p+1)^n\)</span>个点</li>
</ul>
<p><span class="math display">\[
x_{(i_1,...,i_n)} = (\frac{i_1}{p},\frac{i_2}{p},...,\frac{i_n}{p})^T
\]</span></p>
<p>​ 其中<span class="math inline">\((i_1,...,i_n) \in \{0,...,p
\}^n\)</span></p>
<ul>
<li>在所有的点中找到一个点<span class="math inline">\(\bar{x}\)</span>,其对应的目标函数的值最小</li>
<li>返回<span class="math inline">\((\bar{x},f(\bar{x}))\)</span>作为结果</li>
</ul>
<p><font color="red">该方法找到的是近似解(approximate
solution)!!!</font></p>
<h2 id="评估结果">4.评估结果</h2>
<p><font color="red">定理</font>： 令<span class="math inline">\(f^*\)</span>作为该问题的<font color="red">全局最优解</font>,于是
<span class="math display">\[
f(\bar{x})  - f^* \le \frac{L}{2p}
\]</span></p>
<p><font color="red">直观理解</font>：</p>
<p>这些点均匀分布于边长为1的空间中，任意相邻两点之间距离为<span class="math inline">\(\frac{1}{p}\)</span>,于是全局最优解坐标距离近似解不超过<span class="math inline">\(\frac{1}{2p}\)</span>,对应到值域乘上一个斜率系数<span class="math inline">\(L\)</span>即可。</p>
<p><font color="red">严格证明</font>：</p>
<p>令<span class="math inline">\(x_*\)</span>为全局最优解对应的点，于是存在 <span class="math display">\[
x \equiv x_{(i_1,...,i_n)} \le x_* \le x_{(i_1+1,...,i_n+1)} \equiv y
\]</span></p>
<blockquote>
<p>ps: 对于n维向量，当且仅当任意<span class="math inline">\(x^{(i)} \le
y^{(i)}\)</span>时，写作<span class="math inline">\(x \le y\)</span></p>
</blockquote>
<p>其中<span class="math inline">\(y^{(i)} - x^{(i)} =
\frac{1}{p}\)</span>且 <span class="math display">\[
x_*^{(i)} \in [x^{(i)},y^{(i)}]
\]</span> 令<span class="math inline">\(\hat{x} =
(x+y)/2\)</span>.构造一个点<span class="math inline">\(\tilde{x}\)</span>如下： <span class="math display">\[
\tilde{x}^{(i)} =  \begin{cases}  y^{(i)} &amp; if \space
\tilde{x}^{(i)} \le x_*^{(i)} \\ x^{(i)} &amp; otherwise\end{cases}
\]</span> 显然<span class="math inline">\(|\tilde{x}^{(i)}-x_*^{(i)}|\le
\frac{1}{2p}\)</span>,因此 <span class="math display">\[
||\tilde{x}-x_*||_{\infty} = \underset{1\le i \le
n}{max}|\tilde{x}^{(i)}-x_*^{(i)}|\le \frac{1}{2p}
\]</span> 由于<span class="math inline">\(\tilde{x}\)</span>属于网格，于是 <span class="math display">\[
f(\bar{x})-f(x_*) \le f(\tilde{x})-f(x_*) \le
L||\tilde{x}-x_*||_{\infty} \le \frac{L}{2p}
\]</span> 得证！</p>
<p>于是可以写作 <span class="math display">\[
Find \space \bar{x} \in B_n : f(\bar{x}) - f^* \le \epsilon
\]</span></p>
<h2 id="推论">5.推论</h2>
<p><span class="math inline">\(Method \mathscr{G}\)</span>的复杂度为
<span class="math display">\[
\mathscr{A}(\mathscr{G}) = (\lfloor \frac{L}{2\epsilon} \rfloor+2)^n
\]</span> 证明：</p>
<p>当<span class="math inline">\(p\)</span>取<span class="math inline">\(\lfloor \frac{L}{2\epsilon}
\rfloor+1\)</span>时，有<span class="math inline">\(p \ge
\frac{L}{2\epsilon}\)</span>，此时满足<span class="math inline">\(f(\bar{x}) - f^* \le \frac{L}{2p} \le
\epsilon\)</span></p>
<p>于是由<span class="math inline">\((p+1)^n\)</span> 可以得出 <span class="math inline">\((\lfloor \frac{L}{2\epsilon} \rfloor+2)^n\)</span>
.</p>
<p>这就是上界(upper complexity
bound),仅代表最坏情况下的性能，无法展现更优情况下的性能，无法反映这是否是最优算法</p>
<p>由此引出下界(lower complexity bound) <span class="math display">\[
for \space \epsilon &lt; \frac{1}{2}L,\space lower \space bound = \space
(\lfloor \frac{L}{2\epsilon} \rfloor)^n
\]</span></p>
]]></content>
      <categories>
        <category>凸优化</category>
      </categories>
      <tags>
        <tag>凸优化</tag>
      </tags>
  </entry>
  <entry>
    <title>Convex Function</title>
    <url>/2022/10/06/Convex-Function/</url>
    <content><![CDATA[<style> 
    .markdown-body {
      font-family: Microsoft JhengHei, SimHei;
      font-size: 16px;
    }
</style>
<h1 align="center">
Convex Function
</h1>
<h2 id="definition">1.Definition</h2>
<p>Definition 15:</p>
<p>A set <span class="math inline">\(\mathcal{Q} \subseteq
\mathbb{R}^n\)</span> is called <font color="orange">convex</font> if for
any <span class="math inline">\(\pmb{x},\pmb{y} \in \mathcal{Q}\)</span>
and <span class="math inline">\(\alpha\)</span> from [0,1] we have <span class="math display">\[
\alpha \pmb{x} + (1 - \alpha) \pmb{y} \in \mathcal{Q} \tag{10}
\]</span></p>
<hr>
<p>Definition 16:</p>
<p>A continuously differentiable function <span class="math inline">\(f
(·)\)</span> is called <font color="orange">convex</font> on a convex set
<span class="math inline">\(\mathcal{Q}\)</span> (notation <span class="math inline">\(f \in \mathcal{F}^1(\mathcal{Q}^n )\)</span> if
for any <span class="math inline">\(x, y \in \mathcal{Q}\)</span> we
have <span class="math display">\[
f(\pmb{y}) \ge f(\pmb{x}) + \langle \nabla
f(\pmb{x}),\pmb{y}-\pmb{x}\rangle \tag{11}
\]</span> if <span class="math inline">\(-f(\pmb{x})\)</span> is convex,
we call <span class="math inline">\(f(\pmb{x})\)</span>
<font color="orange">concave</font>.</p>
<hr>
<h2 id="properties-of-the-convex-function">2.Properties of the Convex
Function</h2>
<p>Lemma 18:</p>
<p>if <span class="math inline">\(f_1\)</span> and <span class="math inline">\(f_2\)</span> belong to <span class="math inline">\(\mathcal{F}^1(\mathbb{R}^n)\)</span>, and <span class="math inline">\(\alpha , \beta \ge 0\)</span>, then the function
<span class="math inline">\(f = \alpha f_1 + \beta f_2\)</span> also
belong to <span class="math inline">\(\mathcal{F}^1(\mathbb{R}^n
)\)</span>.</p>
<hr>
<p>Proof.</p>
<p>for any <span class="math inline">\(\pmb{x} ,\pmb{y} \in
\mathbb{R}^n\)</span>, we have <span class="math display">\[
f_1(\pmb{y}) \ge f_1(\pmb{x}) + \langle \nabla
f_1(\pmb{x}),\pmb{y}-\pmb{x}\rangle \tag{①}
\]</span></p>
<p><span class="math display">\[
f_2(\pmb{y}) \ge f_2(\pmb{x}) + \langle \nabla
f_2(\pmb{x}),\pmb{y}-\pmb{x}\rangle \tag{②}
\]</span></p>
<p>then <span class="math inline">\(\alpha \cdot\)</span>① + <span class="math inline">\(\beta \cdot\)</span>② .</p>
<hr>
<p>Lemma 19:</p>
<p>if <span class="math inline">\(f \in
\mathcal{F}^1(\mathbb{R}^n)\)</span>. <span class="math inline">\(b \in
\mathbb{R}^m\)</span>, and <span class="math inline">\(A : \mathbb{R}^n
\rightarrow \mathbb{R}^m\)</span>, then <span class="math display">\[
\phi(\pmb{x}) = f(A\pmb{x}+\pmb{b}) \in \mathcal{F}^1(\mathbb{R}^n)
\]</span></p>
<hr>
<p>Proof.</p>
<p>Define <span class="math inline">\(\overline{\pmb{x}} =
A\pmb{x}+\pmb{b}\)</span>, <span class="math inline">\(\overline{\pmb{y}} = A\pmb{y}+\pmb{b}\)</span>.
since <span class="math inline">\(\phi&#39;(\pmb{x}) = A^T \nabla
f(A\pmb{x}+\pmb{b})\)</span>, we have <span class="math display">\[
\begin{aligned}
\phi(\pmb{y}) = f(\overline{\pmb{y}}) &amp;\ge f(\overline{\pmb{x}}) +
\langle \nabla
f(\overline{\pmb{x}}),\overline{\pmb{y}}-\overline{\pmb{x}}\rangle \\
&amp; = \phi(\pmb{x}) + \langle \nabla
f(\overline{\pmb{x}}),A(\pmb{y}-\pmb{x})\rangle \\
&amp; = \phi(\pmb{x}) + \langle A^T \nabla
f(\overline{\pmb{x}}),(\pmb{y}-\pmb{x})\rangle \\
&amp; =\phi(\pmb{x}) + \langle \phi(\pmb{x}),(\pmb{y}-\pmb{x})\rangle
\end{aligned}
\]</span></p>
<hr>
<p>Lemma 20:</p>
<p>If <span class="math inline">\(f_i(\pmb{x})\)</span>, <span class="math inline">\(i \in I\)</span>, are convex, then <span class="math display">\[
g(\pmb{x}) = \underset{i \in I}{max}f_i(\pmb{x})
\]</span> is also convex.</p>
<hr>
<p>Lemma 21:</p>
<ul>
<li><p>If <span class="math inline">\(f\)</span> is a convex function on
<span class="math inline">\(\mathbb{R}^n\)</span> and <span class="math inline">\(F (·)\)</span> is a convex and
<font color="orange">non­-decreasing</font> function on <span class="math inline">\(\mathbb{R}\)</span>, then <span class="math inline">\(g (x) = F (f (x))\)</span> is convex.</p></li>
<li><p>If <span class="math inline">\(f_i , i = 1, . . . , m\)</span>
are convex functions on <span class="math inline">\(\mathbb{R}^n\)</span> and <span class="math inline">\(F (y_1 , . . . , y_m )\)</span> is convex and
<font color="orange">non-­decreasing</font> (component­wise) in each
argument, then <span class="math display">\[
g(\pmb{x}) = F(f_1(\pmb{x}),...,f_m(\pmb{x}))
\]</span> is convex.</p></li>
</ul>
<hr>
<p>Lemma 22:</p>
<p>If <span class="math inline">\(f(\pmb{x},\pmb{y})\)</span> is convex
in <span class="math inline">\((\pmb{x},\pmb{y}) \in
\mathbb{R}^n\)</span> and <span class="math inline">\(Y\)</span> is a
convex set, then <span class="math display">\[
g(\pmb{x}) = \underset{\pmb{y} \in Y}{\rm{inf}} \space
f(\pmb{x},\pmb{y})
\]</span> is convex.</p>
<hr>
<h2 id="equivalent-definitions">3.Equivalent Definitions</h2>
<p>Theorem 23</p>
<p>A continuously <font color="orange">differentiable</font> function
<span class="math inline">\(f\)</span> belongs to the class <span class="math inline">\(\mathcal{F}^1(\mathbb{R}^n)\)</span> if and only
if for any <span class="math inline">\(\pmb{x},\pmb{y} \in
\mathbb{R}^n\)</span> and <span class="math inline">\(\alpha \in
[0,1]\)</span> we have <span class="math display">\[
f(\alpha \pmb{x} + (1 - \alpha)\pmb{y}) \le \alpha f(\pmb{x}) + (1 -
\alpha) f(\pmb{y}) \tag{12}
\]</span></p>
<hr>
<p>Theorem 24</p>
<p>A continuously <font color="orange">differentiable</font> function
<span class="math inline">\(f\)</span> belongs to the class <span class="math inline">\(\mathcal{F}^1(\mathbb{R}^n)\)</span> if and only
if for any <span class="math inline">\(\pmb{x},\pmb{y} \in
\mathbb{R}^n\)</span> we have</p>
<p><span class="math display">\[
\langle \nabla f(\pmb{x}) - \nabla f(\pmb{y}),\pmb{x} - \pmb{y} \rangle
\ge 0 \tag{13}
\]</span></p>
<hr>
<p>Theorem 25</p>
<p>A twice continuously <font color="orange">differentiable</font>
function <span class="math inline">\(f\)</span> belongs to the class
<span class="math inline">\(\mathcal{F}^2 (\mathbb{R}^n )\)</span> if
and only if for any <span class="math inline">\(x \in
\mathbb{R}^n\)</span> we have <span class="math display">\[
\nabla ^2 f(\pmb{x}) \succeq 0 \tag{14}
\]</span></p>
<hr>
<h2 id="necessary-and-sufficient-conditions-for-the-class-mathcalf11_lmathbbrn">4.Necessary
and Sufficient Conditions for The Class <span class="math inline">\(\mathcal{F}^{1,1}_{L}(\mathbb{R}^n)\)</span></h2>
<p>Theorem 2.1.5</p>
<p>All conditions below, holding for all <span class="math inline">\(x,y
\in R^n\)</span> and <span class="math inline">\(\alpha\)</span> from
<span class="math inline">\([0,1]\)</span>, are equivalent to inclusion
<span class="math inline">\(f \in \mathcal{F}^{1,1}_{L}(R^n)\)</span>
<span class="math display">\[
0 \le f(y)-f(x)-\langle f&#39;(x),y-x \rangle \le \frac{L}{2} ||x-y||^2
\tag{2.1.6}
\]</span></p>
<p><span class="math display">\[
f(x) + \langle f&#39;(x),y-x \rangle +
\frac{1}{2L}||f&#39;(x)-f&#39;(y)||^2 \le f(y) \tag{2.1.7}
\]</span></p>
<p><span class="math display">\[
\frac{1}{L}||f&#39;(x)-f&#39;(y)||^2 \le \langle f&#39;(x)-f&#39;(y)
,x-y \rangle \tag{2.1.8}
\]</span></p>
<p><span class="math display">\[
\langle f&#39;(x)-f&#39;(y),x-y \rangle \le L||x-y||^2 \tag{2.1.9}
\]</span></p>
<p><span class="math display">\[
\alpha f(x) + (1-\alpha) f(y) \ge f(\alpha x +
(1-\alpha)y)+\frac{\alpha(1-\alpha)}{2L}||f&#39;(x)-f&#39;(y)||^2
\tag{2.1.10}
\]</span></p>
<p><span class="math display">\[
\alpha f(x) + (1-\alpha) f(y) \le f(\alpha x +(1-\alpha)y) +
\alpha(1-\alpha)\frac{L}{2}||x-y||^2 \tag{2.1.11}
\]</span></p>
<h2 id="necessary-and-sufficient-conditions-for-the-class-mathcalf21_lmathbbrn">5.Necessary
and Sufficient Conditions for The Class <span class="math inline">\(\mathcal{F}^{2,1}_{L}(\mathbb{R}^n)\)</span></h2>
<p>Theorem 2.1.6</p>
<p>Two times continuously differentiable function $f $ belongs to <span class="math inline">\(\mathcal{F}^{2,1}_{L}(R^n)\)</span> if and only
for <span class="math inline">\(\forall x \in R^n\)</span> we have <span class="math display">\[
0 \preceq f&#39;&#39;(x) \preceq LI_n \tag{2.1.12}
\]</span></p>
]]></content>
      <categories>
        <category>凸优化</category>
      </categories>
      <tags>
        <tag>凸优化</tag>
      </tags>
  </entry>
  <entry>
    <title>Deterministic Finite Automata</title>
    <url>/2022/10/10/Deterministic-Finite-Automata/</url>
    <content><![CDATA[<style> 
    .markdown-body {
      font-family: Microsoft JhengHei, SimHei;
      font-size: 16px;
    }
</style>
<h1 align="center">
Deterministic Finite Automata
</h1>
<h2 id="structure-of-dfa">1.Structure of DFA</h2>
<figure>
<img src="/2022/10/10/Deterministic-Finite-Automata/1.png" alt="1">
<figcaption aria-hidden="true">1</figcaption>
</figure>
<ul>
<li>Input tape</li>
<li>Reading head</li>
<li>Finite control (with initial state)</li>
</ul>
<hr>
<p>Definition 2.1.1: A DFA is a quintuple <span class="math inline">\(M=(K,\Sigma,\delta,s,F)\)</span> where</p>
<ul>
<li><span class="math inline">\(K\)</span> is a finite set of
<font color="orange">states</font></li>
<li><span class="math inline">\(\Sigma\)</span> is an
<font color="orange">alphabet</font></li>
<li><span class="math inline">\(s \in K\)</span> is the
<font color="orange">initial state</font></li>
<li><span class="math inline">\(F \subseteq K\)</span> is the set of
<font color="orange">final states</font></li>
<li><span class="math inline">\(\delta\)</span> is the
<font color="orange">transition function</font>, a function from <span class="math inline">\(K \times \Sigma\)</span> to <span class="math inline">\(K\)</span></li>
</ul>
<hr>
<h2 id="binary-relation-vdash_m">2.Binary Relation <span class="math inline">\(\vdash_M\)</span></h2>
<p>If <span class="math inline">\((q,w)\)</span> and <span class="math inline">\((q&#39;,w&#39;)\)</span> are two configurations of
<span class="math inline">\(M\)</span>, then <span class="math inline">\(\textcolor{orange}{(q,w) \vdash_M
(q&#39;,w&#39;)}\)</span> if and only if <span class="math inline">\(w =
aw&#39;\)</span> for some symbol <span class="math inline">\(\textcolor{orange}{a \in \Sigma}\)</span>, and
<span class="math inline">\(\textcolor{orange}{\delta(q,a) =
q&#39;}\)</span>.</p>
<p>In this case we say that <span class="math inline">\((q,w)\)</span>
<font color="orange">yields</font> <span class="math inline">\((q&#39;,w&#39;)\)</span> <font color="orange">in one
step</font>.</p>
<p>In fact <span class="math inline">\(\vdash_M\)</span> is a function
from <span class="math inline">\(K \times \Sigma^+\)</span> to <span class="math inline">\(K \times \Sigma^*\)</span>.</p>
<p>If <span class="math inline">\(\vdash_M\)</span> is
<font color="orange">reflexive</font>, <font color="orange">tansitive</font>
closure; we denote it by <span class="math inline">\(\vdash_M^*\)</span>.</p>
<p>If there is a state <span class="math inline">\(q\in F\)</span> such
that <span class="math inline">\((s,w) \vdash_M^*
(q,\textcolor{orange}{e})\)</span>. We say <font color="orange">the
language accepted by</font> <span class="math inline">\(M\)</span>.
<span class="math inline">\(L(M)\)</span> is the set of all strings
accepted by <span class="math inline">\(M\)</span>.</p>
<h2 id="example-2.1.1">3.Example 2.1.1</h2>
<p>Let <span class="math inline">\(M\)</span> be the DFA <span class="math inline">\((K,\Sigma,\delta,s,F)\)</span>,<br>where <span class="math display">\[
\begin{aligned}
K &amp;= \{q_0,q_1\},\\
\Sigma &amp;= \{ a,b \},\\
s &amp;= q_0,\\
F &amp;= \{q_0\},
\end{aligned}
\]</span> and <span class="math inline">\(\delta\)</span> is the funtion
below.</p>
<table>
<thead>
<tr class="header">
<th><span class="math inline">\(q\)</span></th>
<th><span class="math inline">\(\sigma\)</span></th>
<th><span class="math inline">\(\delta(q,\sigma)\)</span></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td><span class="math inline">\(q_0\)</span></td>
<td>a</td>
<td><span class="math inline">\(q_0\)</span></td>
</tr>
<tr class="even">
<td><span class="math inline">\(q_0\)</span></td>
<td>b</td>
<td><span class="math inline">\(q_1\)</span></td>
</tr>
<tr class="odd">
<td><span class="math inline">\(q_1\)</span></td>
<td>a</td>
<td><span class="math inline">\(q_1\)</span></td>
</tr>
<tr class="even">
<td><span class="math inline">\(q_1\)</span></td>
<td>b</td>
<td><span class="math inline">\(q_0\)</span></td>
</tr>
</tbody>
</table>
<p>If <span class="math inline">\(M\)</span> is given the input <span class="math inline">\(aabba\)</span>, its initial configuration is <span class="math inline">\((q_0,aabba)\)</span>. Then <span class="math display">\[
\begin{aligned}
(q_0,aabba) &amp;\vdash_M (q_0,abba)\\
&amp;\vdash_M (q_0,bba)\\
&amp;\vdash_M (q_1,ba)\\
&amp;\vdash_M (q_0,a)\\
&amp;\vdash_M (q_0,e)
\end{aligned}
\]</span> Therefore <span class="math inline">\((q_0,aabba)
\vdash_M^*(q_0,e)\)</span>, and so <span class="math inline">\(aabba\)</span> is accepted by <span class="math inline">\(M\)</span>.</p>
<hr>
<p>To be clearer, a more convenient graphical representation called
<font color="orange">state diagram</font> is used.</p>
<figure>
<img src="/2022/10/10/Deterministic-Finite-Automata/2.png" alt="2">
<figcaption aria-hidden="true">2</figcaption>
</figure>
<hr>
<h2 id="example-2.1.2">4.Example 2.1.2</h2>
<p>Lets us design a deterministic finite automaton <span class="math inline">\(M\)</span> that accepts language <span class="math inline">\(L(M)=\{w\in\{a,b\}^*:w \; does \; not \; contain
\; three \; consecutive \; b&#39;s\}\)</span>.</p>
<p>Let <span class="math inline">\(M\)</span> be the DFA <span class="math inline">\((K,\Sigma,\delta,s,F)\)</span>,<br>where <span class="math display">\[
\begin{aligned}
K &amp;= \{q_0,q_1,q_2,q_3\},\\
\Sigma &amp;= \{ a,b \},\\
s &amp;= q_0,\\
F &amp;= \{q_0,q_1,q_2\},
\end{aligned}
\]</span> and <span class="math inline">\(\delta\)</span> is the funtion
below.</p>
<table>
<thead>
<tr class="header">
<th><span class="math inline">\(q\)</span></th>
<th><span class="math inline">\(\sigma\)</span></th>
<th><span class="math inline">\(\delta(q,\sigma)\)</span></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td><span class="math inline">\(q_0\)</span></td>
<td><span class="math inline">\(a\)</span></td>
<td><span class="math inline">\(q_0\)</span></td>
</tr>
<tr class="even">
<td><span class="math inline">\(q_0\)</span></td>
<td><span class="math inline">\(b\)</span></td>
<td><span class="math inline">\(q_1\)</span></td>
</tr>
<tr class="odd">
<td><span class="math inline">\(q_1\)</span></td>
<td><span class="math inline">\(a\)</span></td>
<td><span class="math inline">\(q_0\)</span></td>
</tr>
<tr class="even">
<td><span class="math inline">\(q_1\)</span></td>
<td><span class="math inline">\(b\)</span></td>
<td><span class="math inline">\(q_2\)</span></td>
</tr>
<tr class="odd">
<td><span class="math inline">\(q_2\)</span></td>
<td><span class="math inline">\(a\)</span></td>
<td><span class="math inline">\(q_0\)</span></td>
</tr>
<tr class="even">
<td><span class="math inline">\(q_2\)</span></td>
<td><span class="math inline">\(b\)</span></td>
<td><span class="math inline">\(q_3\)</span></td>
</tr>
<tr class="odd">
<td><span class="math inline">\(q_3\)</span></td>
<td><span class="math inline">\(a\)</span></td>
<td><span class="math inline">\(q_3\)</span></td>
</tr>
<tr class="even">
<td>$q_3 $</td>
<td><span class="math inline">\(b\)</span></td>
<td><span class="math inline">\(q_3\)</span></td>
</tr>
</tbody>
</table>
<p>state diagram:</p>
<figure>
<img src="/2022/10/10/Deterministic-Finite-Automata/3.png" alt="3">
<figcaption aria-hidden="true">3</figcaption>
</figure>
<p><span class="math inline">\(q_3\)</span> is not final state, is said
to be a <font color="orange">dead state</font>.</p>
]]></content>
      <categories>
        <category>计算理论</category>
      </categories>
      <tags>
        <tag>计算理论</tag>
      </tags>
  </entry>
  <entry>
    <title>Introduction to Operating System</title>
    <url>/2022/09/21/Introduction-to-Operating-System/</url>
    <content><![CDATA[<style> 
    .markdown-body {
      font-family: Microsoft JhengHei, SimHei;
      font-size: 16px;
    }
</style>
<h1 align="center">
Introduction to Operating System
</h1>
<h2 id="what-operating-systems-do">1.What Operating Systems Do</h2>
<p>A computer system can be divided roughly into four components:</p>
<ul>
<li>the <font color="red"><strong>hardware</strong></font></li>
<li>the <font color="red"><strong>operating system</strong></font></li>
<li>the <font color="red"><strong>application
programs</strong></font></li>
<li>a <font color="red"><strong>user</strong></font></li>
</ul>
<p><img src="/2022/09/21/Introduction-to-Operating-System/1.png" alt="1" style="zoom: 67%;"></p>
<p>The operating system <font color="red"><strong>controls the
hardware</strong></font> <br>and <font color="red"><strong>coordinates
its use among the various application programs</strong></font> <br>for
the various users.</p>
<p>For Users:</p>
<ul>
<li>the operating system is designed mostly for
<font color="red"><strong>ease of use</strong></font>,<br>with some
attention paid to <font color="red"><strong>performance and
security</strong></font></li>
</ul>
<p>For System:</p>
<ul>
<li>we can view an operating system as a
<font color="red"><strong>resource allocator</strong></font></li>
</ul>
<h2 id="computer-system-organization">2.Computer System
Organization</h2>
<p>Computer System consists of:<br><font color="red"><strong>one or more
CPUs</strong></font> and <font color="red"><strong>a number of device
controllers</strong></font><br>connected through
<font color="red"><strong>a commom bus</strong></font><br>that provides
access between components and shared memory</p>
<p><img src="/2022/09/21/Introduction-to-Operating-System/2.png" alt="2" style="zoom:67%;"></p>
<p><strong>Device Driver</strong>:</p>
<ul>
<li>unserstands the device controller.</li>
<li>provides the rest of the operating system with
<font color="red"><strong>a uniform interface</strong></font> to the
device.</li>
</ul>
<p><strong>Interrupts</strong>:</p>
<p>When the CPU is interrupted, it stops what it is doing and
immediately transfers execution to a fixed location.</p>
<h2 id="computer-system-architecture">3.Computer System
Architecture</h2>
<ul>
<li>Single-Processor Systems</li>
<li>Multiprocessor Systems</li>
<li>Clustered Systems</li>
</ul>
]]></content>
      <categories>
        <category>操作系统</category>
      </categories>
      <tags>
        <tag>操作系统</tag>
      </tags>
  </entry>
  <entry>
    <title>LaTex符号对照表</title>
    <url>/2022/09/26/LaTex%E7%AC%A6%E5%8F%B7%E5%AF%B9%E7%85%A7%E8%A1%A8/</url>
    <content><![CDATA[<style> 
    .markdown-body {
      font-family: Microsoft JhengHei, SimHei;
      font-size: 16px;
    }
</style>
<h1 align="center">
LaTex符号对照表
</h1>
<h2 id="不同字体">1.不同字体</h2>
<table>
<thead>
<tr class="header">
<th>字体</th>
<th>代码</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td><span class="math inline">\(\mathscr{L}\)</span></td>
<td>\<span class="math inline">\(mathscr\{\}\)</span></td>
</tr>
<tr class="even">
<td><span class="math inline">\(\mathbb{L}\)</span></td>
<td>\<span class="math inline">\(mathbb\{\}\)</span></td>
</tr>
<tr class="odd">
<td><span class="math inline">\(\mathcal{L}\)</span></td>
<td>\<span class="math inline">\(mathcal \{\}\)</span></td>
</tr>
<tr class="even">
<td><span class="math inline">\(\rm{L}\)</span></td>
<td>\<span class="math inline">\(rm\{\}\)</span></td>
</tr>
<tr class="odd">
<td><span class="math inline">\(\mathfrak{L}\)</span></td>
<td>\<span class="math inline">\(mathfrak\{\}\)</span></td>
</tr>
<tr class="even">
<td><span class="math inline">\(\mathbf{L}\)</span></td>
<td>\<span class="math inline">\(mathbf\{\}\)</span></td>
</tr>
</tbody>
</table>
]]></content>
      <categories>
        <category>LaTex</category>
      </categories>
      <tags>
        <tag>LaTex</tag>
      </tags>
  </entry>
  <entry>
    <title>OS Structures</title>
    <url>/2022/09/25/OS-Structures/</url>
    <content><![CDATA[<style> 
    .markdown-body {
      font-family: Microsoft JhengHei, SimHei;
      font-size: 16px;
    }
</style>
<h1 align="center">
OS Structures
</h1>
<h2 id="a-view-of-os-services">1.A View of OS Services</h2>
<figure>
<img src="/2022/09/25/OS-Structures/1.png" alt="1">
<figcaption aria-hidden="true">1</figcaption>
</figure>
<p><code>program execution:</code></p>
<ul>
<li>Load and run a program</li>
<li>Allow a program to end in multiple ways(e.g. with error codes)</li>
</ul>
<p><code>I/O operations:</code></p>
<ul>
<li>Allow programs access to I/O devices</li>
</ul>
<p><code>file systems:</code></p>
<ul>
<li>Provides file/directory abstractions</li>
<li>Allow programs to create/delete/read/write</li>
<li>Implements permissions</li>
</ul>
<p><code>communication:</code></p>
<ul>
<li>Provides abstractions for processes to exchange information(Shared
memory, Message passing)</li>
</ul>
<p><code>error detection:</code></p>
<ul>
<li>The OS needs to be aware of all errors</li>
<li>The OS needs to take action</li>
</ul>
<p><code>resource allocation:</code></p>
<ul>
<li>Decides which process gets which resource when</li>
</ul>
<p><code>accounting:</code></p>
<ul>
<li>Keeps track of how much is used by each user</li>
</ul>
<p><code>protection and security:</code></p>
<ul>
<li>Controls access to resources</li>
<li>Enforces authentication of all users</li>
<li>Allow users to protect their content</li>
</ul>
<h2 id="user-operating-system-interface">2.User Operating System
Interface</h2>
<ul>
<li>CLI, Command Line Interfaces</li>
<li>GUI, Graphical User Interfaces</li>
<li>Touchscreen Interfaces</li>
</ul>
<h2 id="system-calls">3.System Calls</h2>
<p>In <a href="https://en.wikipedia.org/wiki/Computing">computing</a>, a
<strong>system call</strong> (commonly abbreviated to
<strong>syscall</strong>) is the programmatic way in which a <a href="https://en.wikipedia.org/wiki/Computer_program">computer
program</a> requests a service from the <a href="https://en.wikipedia.org/wiki/Kernel_(operating_system)">kernel</a>
of the <a href="https://en.wikipedia.org/wiki/Operating_system">operating
system</a> on which it is executed.</p>
<p>Two ways to write a program</p>
<figure class="highlight c"><table><tr><td class="code"><pre><code class="hljs c"><span class="hljs-meta">#<span class="hljs-keyword">include</span> <span class="hljs-string">&lt;stdio.h&gt;</span></span><br><br><span class="hljs-type">int</span> <span class="hljs-title function_">main</span><span class="hljs-params">()</span> &#123;<br>    <span class="hljs-built_in">printf</span>(<span class="hljs-string">&quot;hello world\n&quot;</span>);<br>    <span class="hljs-keyword">return</span> <span class="hljs-number">0</span>;<br>&#125;<br></code></pre></td></tr></table></figure>
<figure class="highlight c"><table><tr><td class="code"><pre><code class="hljs c"><span class="hljs-meta">#<span class="hljs-keyword">include</span> <span class="hljs-string">&lt;unistd.h&gt;</span></span><br><br><span class="hljs-type">int</span> <span class="hljs-title function_">main</span><span class="hljs-params">()</span> &#123;<br>    write(<span class="hljs-number">1</span>, <span class="hljs-string">&quot;hello world\n&quot;</span>, <span class="hljs-number">13</span>);<br>    <span class="hljs-keyword">return</span> <span class="hljs-number">0</span>;<br>&#125;<br></code></pre></td></tr></table></figure>
<ul>
<li><code>printf</code> is a <font color="red">wrapper</font> of the
<code>write</code> system call</li>
<li>C program invoking <code>printf()</code> library call, which calls
<code>write()</code> system call</li>
</ul>
<p>x86_64 system call</p>
<table>
<thead>
<tr class="header">
<th>NO.</th>
<th>Name</th>
<th>Entry point</th>
<th>Implementation</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>0</td>
<td>read</td>
<td>sys_read</td>
<td>fs/read_write.c</td>
</tr>
<tr class="even">
<td>1</td>
<td>write</td>
<td>sys_write</td>
<td>fs/read_write.c</td>
</tr>
<tr class="odd">
<td>2</td>
<td>open</td>
<td>sys_open</td>
<td>fs/open.c</td>
</tr>
<tr class="even">
<td>3</td>
<td>close</td>
<td>sys_close</td>
<td>fs/open.c</td>
</tr>
<tr class="odd">
<td>4</td>
<td>stat</td>
<td>sys_newstat</td>
<td>fs/stat.c</td>
</tr>
<tr class="even">
<td>5</td>
<td>fstat</td>
<td>sys_newfstat</td>
<td>fs/stat.c</td>
</tr>
</tbody>
</table>
<p><code>write()</code> system call go through</p>
<ul>
<li><code>syscall</code> instruction on x86_64
<br>(<code>int $0x80</code> on 32-bit x86; <code>svc</code> on
arm64)</li>
<li>Move syscall number <code>0x1</code> to <code>%eax</code></li>
<li><code>syscall</code> will <font color="red">transfer the control flow
from user to kernel</font></li>
</ul>
<p>Kernel space</p>
<ul>
<li><code>kernel_entry</code> code will be called (<font color="red">saved
all user space registers</font>)</li>
<li>Calls <code>write</code> syscall handler (get from
syscall_table,which is an array)</li>
<li>After write finish, call
<code>ret_to_user</code><br>(<font color="red">restore all saved user
space registers,  transfer control flow to user space</font>)</li>
</ul>
<figure>
<img src="/2022/09/25/OS-Structures/2.png" alt="2">
<figcaption aria-hidden="true">2</figcaption>
</figure>
<p>Time Spent in System Calls</p>
<ul>
<li><code>real time:</code> wall-clock time (elapsed time, execution
time, run time)</li>
<li><code>user time:</code> time spent in user code (user mode)</li>
<li><code>system time:</code> time spent in system calls (kernel
mode)</li>
</ul>
<p>System Call Parameter Passing</p>
<ul>
<li>pass the parameters in <font color="red">registers</font></li>
<li>parameters stored in a block, or table, in
<font color="red">memory</font>, and address of block passed as a
parameter in a register</li>
<li>parameters placed in the <font color="red">stack</font></li>
</ul>
<p>Types of System Calls</p>
<p><code>Process cotrol</code></p>
<ul>
<li>create process, terminate process</li>
<li>end, abort</li>
<li>load, execute</li>
<li>get process attributes, set process attributes</li>
<li>wait for time</li>
<li>wait event, signal event</li>
<li>allocate and free memory</li>
<li>Dump memory if error</li>
<li>Debugger for determining bugs, single step execution</li>
<li>Locks for managing access to shared data between processes</li>
</ul>
<p><code>File management</code></p>
<ul>
<li>create file, delete file</li>
<li>open, close file</li>
<li>read, write, reposition</li>
<li>get and set file attributes</li>
</ul>
<p><code>Device management</code></p>
<ul>
<li>request device, release device</li>
<li>read, write, reposition</li>
<li>get device attributes, set device attributes</li>
<li>logically attach or detach devices</li>
</ul>
<p><code>Information maintenance</code></p>
<ul>
<li>get time or date, set time or date</li>
<li>get system data, set system data</li>
<li>get and set process, file, or device attributes</li>
</ul>
<p><code>Communications</code></p>
<ul>
<li>create, delete communication connection</li>
<li>send, receive messages if message passing model to host name or
process name</li>
<li>Shared-memory model create and gain access to memory regions</li>
<li>transfer status information</li>
<li>attach and detach remote devices</li>
</ul>
<p><code>Protection</code></p>
<ul>
<li>Control access to resources</li>
<li>Get and set permissions</li>
<li>Allow and deny user access</li>
</ul>
<h2 id="linkers-and-loaders">4.Linkers and Loaders</h2>
<figure>
<img src="/2022/09/25/OS-Structures/3.png" alt="3">
<figcaption aria-hidden="true">3</figcaption>
</figure>
<h2 id="elfexecutable-and-linkable-format">5.ELF(Executable and Linkable
Format)</h2>
<p><img src="/2022/09/25/OS-Structures/4.png" alt="4" style="zoom: 80%;"></p>
<ul>
<li><code>Program header table</code> and
<code>section header table</code>: for linker and loader</li>
<li><code>.text</code>: code</li>
<li><code>.rodata</code>: initialized read-only data</li>
<li><code>.data</code>: initialized data</li>
<li><code>.bss</code>: uninitialized data</li>
</ul>
<p>Static link</p>
<ul>
<li>All code are packed in single binary, leading to large binary</li>
<li>Does not require dynamic loader</li>
<li>_start is executed after execve system call</li>
</ul>
<p>Dynamic link</p>
<ul>
<li>Reuse libraries to reduce ELF file size</li>
<li>Call more system calls</li>
</ul>
<p>Some facts</p>
<blockquote>
<p>Statically-linked ELF has no .interp section</p>
<p>Dynamically-linked ELF has .interp section</p>
</blockquote>
<blockquote>
<p>Statically-linked ELF, entry points to _start</p>
<p>Dynamically-linked ELF, entry points to loader</p>
</blockquote>
<blockquote>
<p>Kernel setups stack and heap</p>
<p>Loader setups libraries</p>
</blockquote>
<p>Running ELF</p>
<p><code>Statically-linked</code></p>
<figure>
<img src="/2022/09/25/OS-Structures/5.png" alt="5">
<figcaption aria-hidden="true">5</figcaption>
</figure>
<p><code>Dynamically-linked</code></p>
<figure>
<img src="/2022/09/25/OS-Structures/6.png" alt="6">
<figcaption aria-hidden="true">6</figcaption>
</figure>
]]></content>
      <categories>
        <category>操作系统</category>
      </categories>
      <tags>
        <tag>操作系统</tag>
      </tags>
  </entry>
  <entry>
    <title>Processes</title>
    <url>/2022/09/30/Processes/</url>
    <content><![CDATA[<style> 
    .markdown-body {
      font-family: Microsoft JhengHei, SimHei;
      font-size: 16px;
    }
</style>
<h1 align="center">
Processes
</h1>
<h2 id="process-concept">1.Process Concept</h2>
<p><font color="red">A process is a program in execution</font></p>
<ul>
<li><code>program</code>: bytes stored on <font color="red">disk</font> as
part of an executable file</li>
<li>becomes a process when it’s loaded in
<font color="red">memory</font></li>
<li>a unit of <font color="red">resource allocation and
protection</font></li>
</ul>
<p>Process =</p>
<ul>
<li><font color="red">code</font> (also called the
<font color="red">text</font>)</li>
<li><font color="red">data section</font> (global variables)</li>
<li><font color="red">program counter</font> (points to the next
instruction to execute)</li>
<li>content of the processor’s <font color="red">registers</font></li>
<li>a <font color="red">stack</font></li>
<li>a <font color="red">heap</font></li>
</ul>
<p>Process Address Space</p>
<p><img src="/2022/09/30/Processes/1.png" alt="1" style="zoom:50%;"></p>
<p>Memory Layout of a C Program</p>
<figure>
<img src="/2022/09/30/Processes/2.png" alt="2">
<figcaption aria-hidden="true">2</figcaption>
</figure>
<h2 id="process-state">2.Process State</h2>
<p>Some states:</p>
<ul>
<li><code>New</code>: The process is being created</li>
<li><code>Running</code>: Instructions are being executed</li>
<li><code>Waiting</code>: The process is waiting for some events to
occur</li>
<li><code>Ready</code>: The process is waiting to be assigned to a
processor</li>
<li><code>Terminated</code>: The process has finished execution</li>
</ul>
<figure>
<img src="/2022/09/30/Processes/3.png" alt="3">
<figcaption aria-hidden="true">3</figcaption>
</figure>
<h2 id="process-control-block-pcb">3.Process Control Block (PCB)</h2>
<p><font color="red">Each process has and only has a PCB</font></p>
<ul>
<li>Allocate a PCB on new process creation</li>
<li>free the PCB on process termination</li>
</ul>
<p><img src="/2022/09/30/Processes/4.png" alt="4" style="zoom:50%;"></p>
<h2 id="process-creation">4.Process Creation</h2>
<ul>
<li><p>A process may create new processes, in which case it becomes a
parent</p></li>
<li><p>We obtain a tree of processes</p></li>
<li><p>Each process has a pid</p>
<blockquote>
<p>ppid refers to the parent’s pid</p>
</blockquote></li>
</ul>
<p>Example tree:</p>
<figure>
<img src="/2022/09/30/Processes/5.png" alt="5">
<figcaption aria-hidden="true">5</figcaption>
</figure>
<ul>
<li><p>The child may inherit/share some of the resources of its parent,
or may have entirely new ones</p></li>
<li><p>A parent can also pass input to a child</p></li>
<li><p>Upon creation of a child, the parent can either</p>
<blockquote>
<p>continue execution, or</p>
<p>wait for the child’s completion</p>
</blockquote></li>
<li><p>The child could be either</p>
<blockquote>
<p>a clone of the parent (i.e., have a copy of the address space),
or</p>
<p>be an entirely new program</p>
</blockquote></li>
</ul>
<p>The <code>fork()</code> System Call</p>
<ul>
<li><p><code>fork()</code> creates a new process</p></li>
<li><p>The child is is a copy of the parent, but...</p>
<blockquote>
<p>It has a different pid (and thus ppid)</p>
<p>Its resource utilization (so far) is set to 0</p>
</blockquote></li>
<li><p><code>fork()</code> returns the child’s pid to the parent, and 0
to the child</p>
<blockquote>
<p>Each process can find its own pid with the getpid() call, and its
ppid with the getppid() call</p>
</blockquote></li>
<li><p>Both processes continue execution after the call to
<code>fork()</code></p></li>
</ul>
<p>A Typical Example</p>
<figure>
<img src="/2022/09/30/Processes/6.png" alt="6">
<figcaption aria-hidden="true">6</figcaption>
</figure>
<figure>
<img src="/2022/09/30/Processes/7.png" alt="7">
<figcaption aria-hidden="true">7</figcaption>
</figure>
<figure>
<img src="/2022/09/30/Processes/8.png" alt="8">
<figcaption aria-hidden="true">8</figcaption>
</figure>
<figure>
<img src="/2022/09/30/Processes/9.png" alt="9">
<figcaption aria-hidden="true">9</figcaption>
</figure>
<figure>
<img src="/2022/09/30/Processes/10.png" alt="10">
<figcaption aria-hidden="true">10</figcaption>
</figure>
<figure>
<img src="/2022/09/30/Processes/11.png" alt="11">
<figcaption aria-hidden="true">11</figcaption>
</figure>
<figure>
<img src="/2022/09/30/Processes/12.png" alt="12">
<figcaption aria-hidden="true">12</figcaption>
</figure>
<hr>
<p>(Cont.)</p>
<ul>
<li><p>Address space</p>
<blockquote>
<p>Child duplicate of parent</p>
<p>Child has a program loaded into it</p>
</blockquote></li>
<li><p>UNIX examples</p>
<blockquote>
<p><code>fork()</code> system call creates new process</p>
<p><code>exec()</code> system call used after a fork() to replace the
process’ memory space with a new program</p>
<p>Parent process calls <code>wait()</code> for the child to
terminate</p>
</blockquote></li>
</ul>
<h2 id="process-terminations">5.Process Terminations</h2>
<ul>
<li><p>A process terminates itself with the <code>exit()</code> system
call</p>
<blockquote>
<p>This call takes as argument an integer that is called the process’
exit/return/error code</p>
</blockquote></li>
<li><p>All resources of a process are deallocated by the OS</p>
<blockquote>
<p>physical and virtual memory, open files, I/O buffers, ...</p>
</blockquote></li>
<li><p>A process can cause the termination of another process</p>
<blockquote>
<p>Using something called “signals” and the <code>kill()</code> system
call</p>
</blockquote></li>
</ul>
<h2 id="processes-and-signals">6.Processes and Signals</h2>
<ul>
<li><p>A process can receive signals, i.e., <font color="red">software
interrupts</font></p>
<blockquote>
<p>It is an asynchronous event that the program must act upon, in some
way</p>
</blockquote></li>
<li><p>Signals have many usages, including process synchronization</p>
<blockquote>
<p>We’ll see other, more powerful and flexible process synchronization
tools</p>
</blockquote></li>
<li><p>The OS defines a number of signals, each with a name and a
number, and some meaning</p></li>
<li><p>Signals happen for various reasons</p>
<blockquote>
<p>^C on the command-line sends a SIGINT signal to the running
command</p>
<p>A segmentation violation sends a SIGBUS signal to the running
process</p>
<p>A process sends a SIGKILL signal to another</p>
</blockquote></li>
</ul>
<p>Kill Command</p>
<figure>
<img src="/2022/09/30/Processes/13.png" alt="13">
<figcaption aria-hidden="true">13</figcaption>
</figure>
<h2 id="process-scheduling">7.Process Scheduling</h2>
<ul>
<li><p>Maximize CPU use, quickly switch processes onto CPU core</p></li>
<li><p><font color="red">Process scheduler</font> selects among
<font color="red">ready processes</font> for next execution on CPU
core</p></li>
<li><p>Maintains <font color="red">scheduling queues</font> of
processes</p>
<blockquote>
<p>Ready queue</p>
<p>Wait queues</p>
</blockquote></li>
</ul>
]]></content>
      <categories>
        <category>操作系统</category>
      </categories>
      <tags>
        <tag>操作系统</tag>
      </tags>
  </entry>
  <entry>
    <title>Hello World</title>
    <url>/2022/08/18/hello-world/</url>
    <content><![CDATA[<p>Welcome to <a href="https://hexo.io/">Hexo</a>! This is your very
first post. Check <a href="https://hexo.io/docs/">documentation</a> for
more info. If you get any problems when using Hexo, you can find the
answer in <a href="https://hexo.io/docs/troubleshooting.html">troubleshooting</a> or
you can ask me on <a href="https://github.com/hexojs/hexo/issues">GitHub</a>.</p>
<h2 id="quick-start">Quick Start</h2>
<h3 id="create-a-new-post">Create a new post</h3>
<figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash">$ hexo new <span class="hljs-string">&quot;My New Post&quot;</span><br></code></pre></td></tr></table></figure>
<p>More info: <a href="https://hexo.io/docs/writing.html">Writing</a></p>
<h3 id="run-server">Run server</h3>
<figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash">$ hexo server<br></code></pre></td></tr></table></figure>
<p>More info: <a href="https://hexo.io/docs/server.html">Server</a></p>
<h3 id="generate-static-files">Generate static files</h3>
<figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash">$ hexo generate<br></code></pre></td></tr></table></figure>
<p>More info: <a href="https://hexo.io/docs/generating.html">Generating</a></p>
<h3 id="deploy-to-remote-sites">Deploy to remote sites</h3>
<figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash">$ hexo deploy<br></code></pre></td></tr></table></figure>
<p>More info: <a href="https://hexo.io/docs/one-command-deployment.html">Deployment</a></p>
]]></content>
  </entry>
  <entry>
    <title>transformation</title>
    <url>/2022/10/03/transformation/</url>
    <content><![CDATA[<style> 
    .markdown-body {
      font-family: Microsoft JhengHei, SimHei;
      font-size: 16px;
    }
</style>
<h1 align="center">
Transformation
</h1>
<h2 id="d-transformation">2D Transformation</h2>
<hr>
<h2 id="scale-transformation">1.Scale Transformation</h2>
<p><img src="/2022/10/03/transformation/1.png" alt="1"> <span class="math display">\[
x&#39; = s x
\]</span></p>
<p><span class="math display">\[
y&#39;=sy
\]</span></p>
<p><span class="math display">\[
\begin{bmatrix}
   x&#39; \\
   y&#39;
  \end{bmatrix}
  =
  \begin{bmatrix}
   s &amp; 0 \\
   0 &amp; s
  \end{bmatrix}
  \begin{bmatrix}
   x \\
   y
  \end{bmatrix}
\]</span></p>
<h2 id="scale-non-uniform">2.Scale (Non-Uniform)</h2>
<p><img src="/2022/10/03/transformation/2.png" alt="2"> <span class="math display">\[
\begin{bmatrix}
   x&#39; \\
   y&#39;
  \end{bmatrix}
  =
  \begin{bmatrix}
   s_x &amp; 0 \\
   0 &amp; s_y
  \end{bmatrix}
  \begin{bmatrix}
   x \\
   y
  \end{bmatrix}
\]</span></p>
<h2 id="reflection-transformation">3.Reflection Transformation</h2>
<p><img src="/2022/10/03/transformation/3.png" alt="3"> <span class="math display">\[
x&#39; = -x
\]</span></p>
<p><span class="math display">\[
y&#39; = y
\]</span></p>
<p><span class="math display">\[
\begin{bmatrix}
   x&#39; \\
   y&#39;
  \end{bmatrix}
  =
  \begin{bmatrix}
   -1 &amp; 0 \\
   0 &amp; 1
  \end{bmatrix}
  \begin{bmatrix}
   x \\
   y
  \end{bmatrix}
\]</span></p>
<h2 id="shear-matrix">4.Shear Matrix</h2>
<p><img src="/2022/10/03/transformation/4.png" alt="4"> <span class="math display">\[
\begin{bmatrix}   x&#39;
\\   y&#39;  \end{bmatrix}  =  \begin{bmatrix}   1 &amp; a \\   0 &amp;
1  \end{bmatrix}  \begin{bmatrix}   x \\   y  \end{bmatrix}
\]</span></p>
<h2 id="rotateabout-the-origin-0-0-ccw-by-default">5.Rotate(about the
origin (0, 0), CCW by default)</h2>
<p><img src="/2022/10/03/transformation/5.png" alt="5"> <span class="math display">\[
\begin{bmatrix}
   x&#39; \\
   y&#39;
  \end{bmatrix}
  =
  \begin{bmatrix}
   cos \theta &amp; -sin \theta \\
   sin \theta &amp; cos \theta
  \end{bmatrix}
  \begin{bmatrix}
   x \\
   y
  \end{bmatrix}
\]</span></p>
<h2 id="linear-transforms-matrices">6.Linear Transforms = Matrices</h2>
<p><span class="math display">\[
x&#39; = ax + by
\]</span></p>
<p><span class="math display">\[
y&#39; = cx + dy
\]</span></p>
<p><span class="math display">\[
\begin{bmatrix}
   x&#39; \\
   y&#39;
  \end{bmatrix}
  =
  \begin{bmatrix}
   a &amp; b \\
   c &amp; d
  \end{bmatrix}
  \begin{bmatrix}
   x \\
   y
  \end{bmatrix}
\]</span></p>
<p><span class="math display">\[
\pmb{X&#39;} = \pmb{M}\pmb{X}
\]</span></p>
<h2 id="homogeneous-coordinates">Homogeneous coordinates</h2>
<hr>
<h2 id="translation">7.Translation</h2>
<p><img src="/2022/10/03/transformation/6.png" alt="6"> <span class="math display">\[
x&#39; = x + t_x
\]</span></p>
<p><span class="math display">\[
y&#39; = y+t_y
\]</span></p>
<p><span class="math display">\[
\begin{bmatrix}
   x&#39; \\
   y&#39;
  \end{bmatrix}
  =
  \begin{bmatrix}
   a &amp; b \\
   c &amp; d
  \end{bmatrix}
  \begin{bmatrix}
   x \\
   y
  \end{bmatrix}
  +
  \begin{bmatrix}
   t_x \\
   t_y
  \end{bmatrix}
\]</span></p>
<h2 id="homogenous-coordinates">8.Homogenous Coordinates</h2>
<p><font color="red">Translation do nothing to vectors, so use
0</font></p>
<ul>
<li><span class="math inline">\(2D \space Point =
(x,y,\textcolor{orange}{1})^T\)</span></li>
<li><span class="math inline">\(2D \space Vector =
(x,y,\textcolor{orange}{0})^T\)</span></li>
</ul>
<p>Matrix Representation <span class="math display">\[
\begin{bmatrix}
   x&#39; \\
   y&#39; \\
   1
  \end{bmatrix}
  =
  \begin{bmatrix}
   a &amp; b &amp; t_x \\
   c &amp; d &amp; t_y \\
   0 &amp; 0 &amp; 1
  \end{bmatrix}
  \begin{bmatrix}
   x \\
   y \\
   1
  \end{bmatrix}
\]</span> <span class="math inline">\(\textcolor{red}{Affine \space map
= linear map + translation}\)</span></p>
<p>Valid operation if w-coordinate of result is 1 or 0</p>
<ul>
<li>vector + vector = vector</li>
<li>point – point = vector</li>
<li>point + vector = point</li>
<li>point + point = ??</li>
</ul>
<p>In homogeneous coordinates, <span class="math display">\[
\begin {bmatrix}
x \\
y \\
w
\end {bmatrix}
is \space the \space 2D \space point \space
\begin {bmatrix}
x/w \\
y/w \\
1
\end {bmatrix}
\]</span></p>
<h2 id="d-transformations-summary">9.2D Transformations Summary</h2>
<p>Scale <span class="math display">\[
\pmb{S}(s_x,s_y) =
\begin{bmatrix}
s_x &amp; 0 &amp; 0 \\
0 &amp; s_y &amp; 0 \\
0 &amp; 0 &amp; 1
\end{bmatrix}
\]</span> Rotation <span class="math display">\[
\pmb{R}(\alpha) =
\begin{bmatrix}
cos \alpha &amp; -sin\alpha &amp; 0 \\
sin \alpha &amp; cos \alpha &amp; 0 \\
0 &amp; 0 &amp; 1
\end{bmatrix}
\]</span> Translation <span class="math display">\[
\pmb{T}(t_x,t_y) =
\begin{bmatrix}
1 &amp; 0 &amp; t_x \\
0 &amp; 1 &amp; t_y \\
0 &amp; 0 &amp; 1
\end{bmatrix}
\]</span></p>
<h2 id="inverse-transform">10.Inverse Transform</h2>
<p><span class="math display">\[
\pmb{M}^{-1}
\]</span></p>
<figure>
<img src="/2022/10/03/transformation/7.png" alt="7">
<figcaption aria-hidden="true">7</figcaption>
</figure>
<h2 id="composing-transforms">11.Composing Transforms</h2>
<p>Sequence of affine transforms A1, A2, A3, ...</p>
<figure>
<img src="/2022/10/03/transformation/8.png" alt="8">
<figcaption aria-hidden="true">8</figcaption>
</figure>
<hr>
<h2 id="d-transformations">3D Transformations</h2>
<hr>
<h2 id="d-transformations-1">1.3D Transformations</h2>
<ul>
<li><span class="math inline">\(3D \space Point =
(x,y,z,\textcolor{orange}{1})^T\)</span></li>
<li><span class="math inline">\(3D \space Vector =
(x,y,z,\textcolor{orange}{0})^T\)</span></li>
</ul>
<p>Matrix Representation <span class="math display">\[
\begin{bmatrix}
   x&#39; \\
   y&#39; \\
   z&#39; \\
   1
  \end{bmatrix}
  =
  \begin{bmatrix}
   a &amp; b &amp; c &amp; t_x \\
   d &amp; e &amp; f &amp; t_y \\
   g &amp; h &amp; i &amp; t_z \\
   0 &amp; 0 &amp; 0 &amp; 1
  \end{bmatrix}
  \begin{bmatrix}
   x \\
   y \\
   z \\
   1
  \end{bmatrix}
\]</span></p>
<h2 id="d-rotation">2.3D Rotation</h2>
<p><span class="math display">\[
\pmb{R}_x(\alpha)
  =
  \begin{bmatrix}
   1 &amp; 0 &amp; 0 &amp; 0 \\
   0 &amp; cos \alpha &amp; -sin \alpha &amp; 0 \\
   0 &amp; sin \alpha &amp; cos \alpha &amp; 0 \\
   0 &amp; 0 &amp; 0 &amp; 1
  \end{bmatrix}
\]</span></p>
<p><span class="math display">\[
\pmb{R}_y(\alpha)
  =
  \begin{bmatrix}
   cos \alpha &amp; 0 &amp; sin \alpha &amp; 0  \\
   0 &amp; 1 &amp; 0 &amp; 0 \\
   -sin \alpha &amp; 0 &amp; cos \alpha &amp; 0 \\
   0 &amp; 0 &amp; 0 &amp; 1
  \end{bmatrix}
\]</span></p>
<p><span class="math display">\[
\pmb{R}_z(\alpha)
  =
  \begin{bmatrix}
   cos \alpha &amp; -sin \alpha &amp; 0 &amp; 0  \\
   sin \alpha &amp; cos \alpha &amp; 0 &amp; 0 \\
   0 &amp; 0 &amp; 1 &amp; 0 \\
   0 &amp; 0 &amp; 0 &amp; 1
  \end{bmatrix}
\]</span></p>
<p>Be Careful!!! <span class="math inline">\(\pmb{R}_y\)</span> is a
little different!!!</p>
<p><span class="math inline">\(\overrightarrow{x} \times
\overrightarrow{y} = \overrightarrow{z}\)</span></p>
<p><span class="math inline">\(\overrightarrow{y} \times
\overrightarrow{z} = \overrightarrow{x}\)</span></p>
<p><span class="math inline">\(\overrightarrow{x} \times
\overrightarrow{z} = \textcolor{orange}{-
\overrightarrow{y}}\)</span></p>
<p>Compose any 3D rotation <span class="math display">\[
\pmb{R}_{xyz}(\alpha,\beta,\gamma) =
\pmb{R}_{x}(\alpha)\pmb{R}_{y}(\beta)\pmb{R}_{z}(\gamma)
\]</span></p>
<h2 id="rodrigues-rotation-formula">3.Rodrigues' Rotation Formula</h2>
<p>Rotation by angle <span class="math inline">\(\pmb{\alpha}\)</span>
aroud axis <span class="math inline">\(\pmb{n}\)</span> <span class="math display">\[
\pmb{R}(\pmb{n},\alpha) =
cos(\alpha)\pmb{I}+(1-cos(\alpha))\pmb{n}\pmb{n}^T + sin(\alpha)
\begin{bmatrix}
0 &amp; -n_z &amp; n_y \\
n_z &amp; 0 &amp; -n_x \\
-n_y &amp; n_x &amp; 0
\end{bmatrix}
\]</span></p>
<hr>
<h2 id="viewing-transformation">Viewing Transformation</h2>
<hr>
<h2 id="view-camera-transformation">1.View / Camera Transformation</h2>
<p>Define the camera</p>
<ul>
<li>Position <span class="math inline">\(\overrightarrow{e}\)</span></li>
<li>Look-at / gaze direction <span class="math inline">\(\hat{g}\)</span></li>
<li>Up direction <span class="math inline">\(\hat{t}\)</span></li>
</ul>
<p><img src="/2022/10/03/transformation/9.png" alt="9" style="zoom:50%;"></p>
<p>We always define a camera:</p>
<p>​ ---- <font color="orange">The origin, up at Y, look at -Z </font></p>
<p><img src="/2022/10/03/transformation/10.png" alt="10" style="zoom:50%;"></p>
<p>Transform the camera by <span class="math inline">\(M_{view}\)</span></p>
<ul>
<li>Translate e to origin</li>
<li>Rotate g to -Z</li>
<li>Rotate t to Y</li>
<li>Rotate (g <span class="math inline">\(\times\)</span> t) to X</li>
</ul>
<p><img src="/2022/10/03/transformation/11.png" alt="11" style="zoom:50%;"></p>
<p><font color="red">For Rotate Matrix: <span class="math inline">\(R^{-1} = R^T\)</span></font></p>
<p>$M_{view} = R_{view}T_{view} $ <span class="math display">\[
T_{view} =
\begin{bmatrix}
1 &amp; 0 &amp; 0 &amp; -x_e \\
0 &amp; 1 &amp; 0 &amp; -y_e \\
0 &amp; 0 &amp; 1 &amp; -z_e \\
0 &amp; 0 &amp; 0 &amp; 1
\end{bmatrix}
\]</span></p>
<p><span class="math display">\[
R_{view}^{-1} =
\begin{bmatrix}
x_{\hat{g} \times \hat{t}} &amp; x_t &amp; x_{-g} &amp; 0 \\
y_{\hat{g} \times \hat{t}} &amp; y_t &amp; y_{-g} &amp; 0 \\
z_{\hat{g} \times \hat{t}} &amp; z_t &amp; z_{-g} &amp; 0 \\
0 &amp; 0 &amp; 0 &amp; 1
\end{bmatrix}
\Rightarrow
R_{view} = (R_{view}^{-1})^T =
\begin{bmatrix}
x_{\hat{g} \times \hat{t}} &amp; y_{\hat{g} \times \hat{t}} &amp;
z_{\hat{g} \times \hat{t}} &amp; 0 \\
x_t &amp; y_t &amp; z_t &amp; 0 \\
x_{-g} &amp; y_{-g} &amp; z_{-g} &amp; 0 \\
0 &amp; 0 &amp; 0 &amp; 1
\end{bmatrix}
\]</span></p>
<h2 id="orthographic-projection">2.Orthographic Projection</h2>
<p>We want to map a cuboid [l, r] x [b, t] x [f, n] to <br>the
“canonical (正则、规范、标准)” cube <span class="math inline">\([-1,
1]^3\)</span></p>
<figure>
<img src="/2022/10/03/transformation/12.png" alt="12">
<figcaption aria-hidden="true">12</figcaption>
</figure>
<p>So <span class="math display">\[
M_{ortho} =
\begin{bmatrix}
\frac{2}{r-l} &amp; 0 &amp; 0 &amp; 0 \\
0 &amp; \frac{2}{t-b} &amp; 0 &amp; 0 \\
0 &amp; 0 &amp; \frac{2}{n-f} &amp; 0 \\
0 &amp; 0 &amp; 0 &amp; 1
\end{bmatrix}
\begin{bmatrix}
1 &amp; 0 &amp; 0 &amp; -\frac{r+l}{2} \\
0 &amp; 1 &amp; 0 &amp; -\frac{t+b}{2} \\
0 &amp; 0 &amp; 1 &amp; -\frac{n+f}{2} \\
0 &amp; 0 &amp; 0 &amp; 1
\end{bmatrix}
\]</span></p>
<h2 id="perspective-projection">3.Perspective Projection</h2>
<figure>
<img src="/2022/10/03/transformation/13.png" alt="13">
<figcaption aria-hidden="true">13</figcaption>
</figure>
<p><span class="math inline">\(M_{persp} =
M_{ortho}M_{ortho-&gt;persp}\)</span></p>
<p>similar triangle:</p>
<figure>
<img src="/2022/10/03/transformation/14.png" alt="14">
<figcaption aria-hidden="true">14</figcaption>
</figure>
<p>the same as y', we have <span class="math display">\[
x&#39; = \frac{n}{z}x
\]</span> so, in homogeneous coordinates <span class="math display">\[
M_{ortho-&gt;persp}
\begin{bmatrix}
x \\
y \\
z \\
1
\end{bmatrix}
=
\begin{bmatrix}
nx/z \\
ny/z \\
? \\
1
\end{bmatrix}
=
\begin{bmatrix}
nx \\
ny \\
? \\
z
\end{bmatrix}
\]</span> Already good enough to figure out part of <span class="math inline">\(M_{ortho-&gt;persp}\)</span> <span class="math display">\[
M_{ortho-&gt;persp} =
\begin{bmatrix}
n &amp; 0 &amp; 0 &amp; 0 \\
0 &amp; n &amp; 0 &amp; 0  \\
? &amp; ? &amp; ? &amp; ?  \\
0 &amp; 0 &amp; 1 &amp; 0
\end{bmatrix}
\]</span> <font color="red">Any point on the near plane will not
change</font> <span class="math display">\[
\begin{bmatrix}
x \\
y \\
n \\
1
\end{bmatrix}
=
\begin{bmatrix}
nx \\
ny \\
n^2 \\
n
\end{bmatrix}
\]</span></p>
<p>then <span class="math display">\[
\begin{bmatrix}
0 &amp; 0 &amp; A &amp; B
\end{bmatrix}
\begin{bmatrix}
x \\
y \\
n \\
1
\end{bmatrix}
=
n^2
\]</span> then <span class="math display">\[
An+B=n^2
\]</span></p>
<p><font color="red">Any point’s z on the far plane will not change</font>
<span class="math display">\[
\begin{bmatrix}
0 \\
0 \\
f \\
1
\end{bmatrix}
=
\begin{bmatrix}
0 \\
0 \\
f^2 \\
f
\end{bmatrix}
\]</span> then <span class="math display">\[
Af+B=f^2
\]</span></p>
<p>As a result <span class="math display">\[
A = n+f \space \space ; \space \space B = -nf
\]</span> Finally <span class="math display">\[
M_{ortho-&gt;persp} =
\begin{bmatrix}
n &amp; 0 &amp; 0 &amp; 0 \\
0 &amp; n &amp; 0 &amp; 0  \\
0 &amp; 0 &amp; n+f &amp; -nf  \\
0 &amp; 0 &amp; 1 &amp; 0
\end{bmatrix}
\]</span></p>
]]></content>
      <categories>
        <category>GAMES101</category>
      </categories>
      <tags>
        <tag>GAMES101</tag>
      </tags>
  </entry>
  <entry>
    <title>Relaxation and approximation</title>
    <url>/2022/09/23/Relaxation-and-approximation/</url>
    <content><![CDATA[<style> 
    .markdown-body {
      font-family: Microsoft JhengHei, SimHei;
      font-size: 16px;
    }
</style>
<h1 align="center">
Relaxation and approximation
</h1>
<h2 id="relaxation松弛">1.Relaxation(松弛)</h2>
<p>定义relaxation sequence:</p>
<blockquote>
<p>We call the sequence <span class="math inline">\(\{a_k
\}^{\infty}_{k=0}\)</span> a relaxation sequence if</p>
<p>​ <span class="math inline">\(a_{k+1} \le a_k\)</span> <span class="math inline">\(\forall k \ge 0\)</span></p>
</blockquote>
<h2 id="approximation近似">2.Approximation(近似)</h2>
<p>用简单的去替代复杂的，并保持原来相似的性质</p>
<p>令<span class="math inline">\(f(x)\)</span>在<span class="math inline">\(\bar{x}\)</span>处可微，于是对于<span class="math inline">\(y \in
R^n\)</span>我们有(<font color="red">泰勒展开</font>) <span class="math display">\[
f(y)=f(\bar{x})+\langle  f^{&#39;}(\bar{x}),y-\bar{x} \rangle +
o(||y-\bar{x}||)
\]</span> 其中<span class="math inline">\(o(r)\)</span>对于<span class="math inline">\(r \ge 0\)</span>有 <span class="math display">\[
\underset{r \rightarrow 0}{lim} \frac{1}{r} o(r) = 0 , \space \space
\space o(0)=0.
\]</span> 同时给出<span class="math inline">\(|| \cdot
||\)</span>在<span class="math inline">\(R^n\)</span>的欧几里得定义:
<span class="math display">\[
||x|| = [\sum_{i=1}^{n}(x^{(i)})^2]^{1/2}
\]</span> 其中的<span class="math inline">\(f^{&#39;}(x)\)</span>是函数<span class="math inline">\(f\)</span>在<span class="math inline">\(x\)</span>处的梯度(gradient) <span class="math display">\[
f&#39;(x) = (\frac{\partial f(x)}{\partial x^{(1)}},...,\frac{\partial
f(x)}{\partial x^{(n)}})^T
\]</span></p>
<h2 id="引理1.2.1">3.引理1.2.1</h2>
<p>定义level set为<span class="math inline">\(\mathscr{L}_f(\alpha)\)</span>: <span class="math display">\[
\mathscr{L}_f(\alpha) = \{ x \in R^n | f(x) \le \alpha \}
\]</span> 同时定义与<span class="math inline">\(\mathscr{L}_f(f(\bar{x}))\)</span>在<span class="math inline">\(\bar{x}\)</span>处<font color="red">相切</font>的方向向量集合:
<span class="math display">\[
S_f(\bar{x}) = \{s \in R^n | s = \underset{f(y_k) =
f(\bar{x})}{\underset{y_k \rightarrow \bar{x}}{lim}}
\frac{y_k-\bar{x}}{||y_k-\bar{x}||} \}
\]</span></p>
<p><font color="red">引理1.2.1</font>: 如果<span class="math inline">\(s
\in S_f(\bar{x})\)</span>,那么<span class="math inline">\(\langle
f&#39;(\bar{x}),s \rangle = 0\)</span>.</p>
<p>证明: 由于<span class="math inline">\(f(y_k) =
f(\bar{x})\)</span>,我们有 <span class="math display">\[
f(y_k)=f(\bar{x})+\langle  f^{&#39;}(\bar{x}),y_k-\bar{x} \rangle +
o(||y_k-\bar{x}||) = f(\bar{x})
\]</span> 因此只需证明<span class="math inline">\(\langle
f^{&#39;}(\bar{x}),y_k-\bar{x} \rangle + o(||y_k-\bar{x}||) =
0\)</span>即可</p>
<p>取极限<span class="math inline">\(y_k \rightarrow
\bar{x}\)</span>时即可得证</p>
<h2 id="证明梯度反方向为局部下降最快方向">4.证明梯度反方向为局部下降最快方向</h2>
<p>令<span class="math inline">\(s\)</span>为<span class="math inline">\(R^n\)</span>中的方向向量，<span class="math inline">\(||s|| = 1\)</span>，局部减小量为 <span class="math display">\[
\Delta(s) = \underset{a \rightarrow 0}{lim} \frac{1}{\alpha}
[f(\bar{x}+\alpha s)-f(\bar{x})]
\]</span> 利用近似(泰勒展开)可以得到<span class="math inline">\(f(\bar{x}+\alpha s)-f(\bar{x})=\alpha \langle
f&#39;(\bar{x}),s \rangle + o(\alpha)\)</span>.因此有 <span class="math display">\[
\Delta (s) = \langle f&#39;(\bar{x}),s \rangle
\]</span> ps: 柯西不等式 <span class="math display">\[
-||x|| \cdot ||y|| \le \langle x,y \rangle \le ||x|| \cdot ||y||
\]</span> 从而有<span class="math inline">\(\Delta(s) = \langle
f&#39;(\bar{x}),s \rangle \ge -||f&#39;(\bar{x})||\)</span>.取 <span class="math display">\[
\bar{s} = -f&#39;(\bar{x}) / ||f&#39;(\bar{x})||
\]</span> 这时能够取到不等式的等号： <span class="math display">\[
\Delta(\bar{s}) = - \langle f&#39;(\bar{x}),f&#39;(\bar{x}) \rangle /
||f&#39;(\bar{x})|| = -||f&#39;(\bar{x})||
\]</span> 因此方向<span class="math inline">\(-f&#39;(\bar{x})\)</span>(antigradient)是局部<font color="red">下降最快</font>的方向</p>
<h2 id="定理1.2.1first-order-optimality-condition">5.定理1.2.1(First-order
optimality condition)</h2>
<p><font color="red">定理1.2.1</font>: 令<span class="math inline">\(x^*\)</span>是局部最小值对应向量，则 <span class="math display">\[
f&#39;(x^*) = 0
\]</span></p>
<h2 id="定理1.2.2second-order-optimality-condition">6.定理1.2.2(Second-order
optimality condition)</h2>
<p>二阶近似 <span class="math display">\[
f(y)=f(\bar{x})+\langle  f^{&#39;}(\bar{x}),y-\bar{x} \rangle +
\frac{1}{2}\langle  f^{&#39;&#39;}(\bar{x})(y-\bar{x}),y-\bar{x}
\rangle   + o(||y-\bar{x}||^2)
\]</span> 其中<span class="math inline">\(n \times n\)</span>矩阵<span class="math inline">\(f&#39;&#39;(x)\)</span>称为<font color="red">黑塞矩阵</font>(Hessian)：
<span class="math display">\[
(f&#39;&#39;(x))^{(i,j)} =
\frac{\partial^2f(x)}{\partial{x}^{(i)}\partial{x}^{(j)}}
\]</span> 黑塞矩阵是对称矩阵: <span class="math display">\[
f&#39;&#39;(x) = [f&#39;&#39;(x)]^T
\]</span> 对称矩阵A是<font color="red">半正定</font>的: <span class="math display">\[
\langle Ax,x \rangle \ge 0 \space \space \space \forall x \in R^n
\]</span> 符号记为 <span class="math display">\[
A \succeq 0
\]</span></p>
<p><font color="red">定理1.2.2</font>: 令<span class="math inline">\(x^*\)</span>是局部最小值对应向量，则 <span class="math display">\[
f&#39;(x^*) = 0, \space \space \space    f&#39;&#39;(x^*) \succeq  0.
\]</span></p>
]]></content>
      <categories>
        <category>凸优化</category>
      </categories>
      <tags>
        <tag>凸优化</tag>
      </tags>
  </entry>
  <entry>
    <title>waitKey</title>
    <url>/2022/10/04/waitKey/</url>
    <content><![CDATA[<style> 
    .markdown-body {
      font-family: Microsoft JhengHei, SimHei;
      font-size: 16px;
    }
</style>
<h1 align="center">
Visual Studio中cv::waitKey无法读取键盘输入问题
</h1>
<h2 id="问题">1.问题</h2>
<p>在Visual Studio
2022中运行c++项目时，opencv库中的<code>cv::waitKey()</code>函数一直无法读取键盘的输入。</p>
<h2 id="原因">2.原因</h2>
<figure>
<img src="/2022/10/04/waitKey/1.png" alt="1">
<figcaption aria-hidden="true">1</figcaption>
</figure>
<p>在Debug模式中动态链接库选择<font color="orange">含有d</font>的.lib文件</p>
<p>同理Release模式对应<font color="orange">不含d</font>的.lib文件</p>
<h2 id="解决方案">3.解决方案</h2>
<p>在工程<code>属性</code>--&gt;<code>链接器</code>--&gt;<code>输入</code>--&gt;<code>附加依赖项</code>中仅保留相关的含d的.lib文件即可</p>
<figure>
<img src="/2022/10/04/waitKey/2.png" alt="2">
<figcaption aria-hidden="true">2</figcaption>
</figure>
]]></content>
      <categories>
        <category>踩坑记录</category>
      </categories>
      <tags>
        <tag>踩坑记录</tag>
      </tags>
  </entry>
  <entry>
    <title>图像匹配</title>
    <url>/2022/10/18/%E5%9B%BE%E5%83%8F%E5%8C%B9%E9%85%8D/</url>
    <content><![CDATA[<style> 
    .markdown-body {
      font-family: Microsoft JhengHei, SimHei;
      font-size: 16px;
    }
</style>
<h1 align="center">
图像匹配
</h1>
<h2 id="图像检测">1.图像检测</h2>
<h3 id="特征点feature-points兴趣点interest-points">1.1特征点(Feature
Points)/兴趣点(Interest Points)</h3>
<figure>
<img src="/2022/10/18/%E5%9B%BE%E5%83%8F%E5%8C%B9%E9%85%8D/1.png" alt="1">
<figcaption aria-hidden="true">1</figcaption>
</figure>
<p>现在我们需要对给定的这两张图片进行匹配，应该选取哪些点？</p>
<p>应当选取<font color="orange">独一无二(uniqueness)</font>的点</p>
<p>如何选取独一无二的点？</p>
<p>先考虑在图片上放置一个能够覆盖若干像素点的小窗口</p>
<figure>
<img src="/2022/10/18/%E5%9B%BE%E5%83%8F%E5%8C%B9%E9%85%8D/2.png" alt="2">
<figcaption aria-hidden="true">2</figcaption>
</figure>
<p>那么如何定义这个小窗口是独一无二的？</p>
<p>当朝任何方向移动这个小窗口，窗口中像素的内容均发生较大变化，即可认为独一无二</p>
<figure>
<img src="/2022/10/18/%E5%9B%BE%E5%83%8F%E5%8C%B9%E9%85%8D/3.png" alt="3">
<figcaption aria-hidden="true">3</figcaption>
</figure>
<p>可以发现，在图像边缘的角落处(corner)能够满足这样的定义</p>
<figure>
<img src="/2022/10/18/%E5%9B%BE%E5%83%8F%E5%8C%B9%E9%85%8D/4.png" alt="4">
<figcaption aria-hidden="true">4</figcaption>
</figure>
<p>先来查看一下图像的梯度分布情况(计算窗口内每个点两个方向的梯度，并以此为坐标放置在平面直角坐标系上)</p>
<figure>
<img src="/2022/10/18/%E5%9B%BE%E5%83%8F%E5%8C%B9%E9%85%8D/5.png" alt="5">
<figcaption aria-hidden="true">5</figcaption>
</figure>
<h3 id="主成分分析">1.2主成分分析</h3>
<p>此处借用主成分分析(PCA)的方法</p>
<p>第一主成分(<span class="math inline">\(1^{st} \; principal \;
conponent\)</span>)对应的方向向量上进行投影后具有最大方差</p>
<p>第二主成分(<span class="math inline">\(2^{nd} \; principal \;
conponent\)</span>)与第一主成分相关系数为0，同时在此前提下具有最大方差的方向</p>
<p>……</p>
<figure>
<img src="/2022/10/18/%E5%9B%BE%E5%83%8F%E5%8C%B9%E9%85%8D/6.png" alt="6">
<figcaption aria-hidden="true">6</figcaption>
</figure>
<p>计算主成分的步骤：</p>
<ul>
<li>将所有数据点减去平均值</li>
<li>计算协方差矩阵<span class="math inline">\(H\)</span></li>
<li>计算对应的特征值和特征向量<span class="math inline">\(H x = \lambda
x\)</span></li>
<li>主成分是依特征值大小排序对应的特征向量</li>
</ul>
<p>此处为二维的情形</p>
<p>于是<span class="math inline">\(H = \begin{bmatrix}a &amp; b \\ c
&amp; d \end{bmatrix}\)</span>, <span class="math inline">\(\lambda_{\pm} = \frac{1}{2}((a+d) \pm \sqrt{4bc +
(c-d)^2})\)</span></p>
<figure>
<img src="/2022/10/18/%E5%9B%BE%E5%83%8F%E5%8C%B9%E9%85%8D/7.png" alt="7">
<figcaption aria-hidden="true">7</figcaption>
</figure>
<p>当两个特征值都很大时为角落点</p>
<h3 id="harris算子">1.3 Harris算子</h3>
<p><span class="math display">\[
f = \frac{\lambda_1 \lambda_2}{\lambda_1 + \lambda_2} =
\frac{ad-bc}{a+d} = \frac{det(H)}{trace(H)}
\]</span></p>
<p><span class="math inline">\(f\)</span>称为响应函数</p>
<p>随着图像平移、旋转，<span class="math inline">\(f\)</span><font color="red">保持不变</font></p>
<p>随着图像缩放，<span class="math inline">\(f\)</span><font color="red">无法保持不变</font></p>
<p>如何匹配缩放变化后的图像？</p>
<p>在两张图上使用不同大小的窗口</p>
<p>如何定义两边窗口的大小？</p>
<p>采用不同大小的窗口进行计算<span class="math inline">\(f\)</span>值，采用<font color="orange">局部最大值</font>对应的窗口大小</p>
<figure>
<img src="/2022/10/18/%E5%9B%BE%E5%83%8F%E5%8C%B9%E9%85%8D/8.png" alt="8">
<figcaption aria-hidden="true">8</figcaption>
</figure>
<h3 id="斑点blob检测">1.4 斑点(blob)检测</h3>
<p>斑点是很好的特征</p>
<figure>
<img src="/2022/10/18/%E5%9B%BE%E5%83%8F%E5%8C%B9%E9%85%8D/9.png" alt="9">
<figcaption aria-hidden="true">9</figcaption>
</figure>
<p>那么如何找到图像中的斑点呢？</p>
<p><font color="orange">斑点在图像强度上具有较大的二阶导数</font></p>
<p>对图像进行<span class="math inline">\(Laplacian\)</span>滤波</p>
<figure>
<img src="/2022/10/18/%E5%9B%BE%E5%83%8F%E5%8C%B9%E9%85%8D/10.png" alt="10">
<figcaption aria-hidden="true">10</figcaption>
</figure>
<h3 id="laplacian算子">1.5<span class="math inline">\(Laplacian\)</span>算子</h3>
<p><span class="math display">\[
\nabla ^2 = \frac{\partial^2}{\partial x^2} + \frac{\partial^2}{\partial
y^2}
\]</span></p>
<p>对离散的像素点进行求导 <span class="math display">\[
\begin{aligned}
\frac{\partial^2 f}{\partial x^2} &amp;= f&#39;(x+0.5) - f&#39;(x-0.5)
\\
&amp;=(f(x+1) - f(x)) - (f(x) - f(x-1)) \\
&amp;=f(x+1) + f(x-1) - 2f(x)
\end{aligned}
\]</span> 于是得到<span class="math inline">\(x \; kernel =
\begin{bmatrix} 1 &amp; -2 &amp;1 \end{bmatrix}\)</span></p>
<p>同理 <span class="math display">\[
\begin{aligned}
\frac{\partial^2 f}{\partial y^2} &amp;= f&#39;(y+0.5) - f&#39;(y-0.5)
\\
&amp;=(f(y+1) - f(y)) - (f(y) - f(y-1)) \\
&amp;=f(y+1) + f(y-1) - 2f(y)
\end{aligned}
\]</span> 于是得到<span class="math inline">\(y \; kernel =
\begin{bmatrix} 1 \\ -2 \\ 1 \end{bmatrix}\)</span></p>
<p>合成后的卷积核为<span class="math inline">\(\begin{bmatrix}0&amp;0&amp;0 \\ 1&amp;-2&amp;1 \\
0&amp;0&amp;0 \end{bmatrix} + \begin{bmatrix}0&amp;1&amp;0 \\
0&amp;-2&amp;0 \\ 0&amp;1&amp;0 \end{bmatrix} =
\begin{bmatrix}0&amp;1&amp;0 \\ 1&amp;-4&amp;1 \\ 0&amp;1&amp;0
\end{bmatrix}\)</span></p>
<h3 id="log滤波">1.6 LoG滤波</h3>
<p>由于<span class="math inline">\(Laplacian\)</span>滤波容易受到噪声干扰，进一步考虑<span class="math inline">\(LoG\)</span>滤波(Laplacian of Gaussian)</p>
<ul>
<li>先对图像高斯滤波</li>
<li>再应用<span class="math inline">\(Laplacian\)</span></li>
</ul>
<h3 id="dog滤波">1.7 DoG滤波</h3>
<p>LoG滤波结果可以由两个高斯滤波的<font color="red">结果之差</font>来近似</p>
<p>比如</p>
<figure>
<img src="/2022/10/18/%E5%9B%BE%E5%83%8F%E5%8C%B9%E9%85%8D/11.png" alt="11">
<figcaption aria-hidden="true">11</figcaption>
</figure>
<figure>
<img src="/2022/10/18/%E5%9B%BE%E5%83%8F%E5%8C%B9%E9%85%8D/12.png" alt="12">
<figcaption aria-hidden="true">12</figcaption>
</figure>
<h2 id="图像描述">2.图像描述</h2>
<p>当我们检测到好的特征点之后，我们要如何去匹配它们？</p>
<figure>
<img src="/2022/10/18/%E5%9B%BE%E5%83%8F%E5%8C%B9%E9%85%8D/13.png" alt="13">
<figcaption aria-hidden="true">13</figcaption>
</figure>
<p>SIFT descriptor</p>
<p>Scale Invariant Feature Transform</p>
<figure>
<img src="/2022/10/18/%E5%9B%BE%E5%83%8F%E5%8C%B9%E9%85%8D/14.png" alt="14">
<figcaption aria-hidden="true">14</figcaption>
</figure>
<p>找到特征点周围像素点的梯度方向，并形成一个直方图，并平移直方图使得数量最多方向位于起始位置</p>
<h2 id="图像匹配">3.图像匹配</h2>
<p>对于给定图1中的特征点如何匹配到图2中的对应特征点</p>
<figure>
<img src="/2022/10/18/%E5%9B%BE%E5%83%8F%E5%8C%B9%E9%85%8D/15.png" alt="15">
<figcaption aria-hidden="true">15</figcaption>
</figure>
<p>可以检测图2中的所有特征点，找到“距离”最小的特征点连接</p>
<p>如何定义“距离”？</p>
<p>可以采用<span class="math inline">\(L_2\)</span>距离<span class="math inline">\(||f_1 - f_2||\)</span></p>
<p>对于<span class="math inline">\(f_1\)</span>找到图2中的<span class="math inline">\(f_2\)</span>特征点，再根据<span class="math inline">\(f_2\)</span>从图1中寻找，若找到仍为<span class="math inline">\(f_1\)</span>，则相互匹配</p>
<p>例子</p>
<figure>
<img src="/2022/10/18/%E5%9B%BE%E5%83%8F%E5%8C%B9%E9%85%8D/16.png" alt="16">
<figcaption aria-hidden="true">16</figcaption>
</figure>
]]></content>
      <categories>
        <category>计算机视觉</category>
      </categories>
      <tags>
        <tag>计算机视觉</tag>
      </tags>
  </entry>
  <entry>
    <title>支持向量机</title>
    <url>/2022/09/29/%E6%94%AF%E6%8C%81%E5%90%91%E9%87%8F%E6%9C%BA/</url>
    <content><![CDATA[<style> 
    .markdown-body {
      font-family: Microsoft JhengHei, SimHei;
      font-size: 16px;
    }
</style>
<h1 align="center">
支持向量机
</h1>
<h2 id="两类别线性可分情形">1.两类别线性可分情形</h2>
<ul>
<li><span class="math inline">\(\pmb{w}^T\pmb{x} &gt;
0\)</span>代表正类别</li>
<li><span class="math inline">\(\pmb{w}^T\pmb{x} &lt;
0\)</span>代表负类别</li>
</ul>
<p><img src="/2022/09/29/%E6%94%AF%E6%8C%81%E5%90%91%E9%87%8F%E6%9C%BA/2.png" alt="1" style="zoom:48%;"></p>
<p>此处的权重向量<span class="math inline">\(\pmb{w}\)</span>被称作<code>separating vector</code>或者<code>solution vector</code></p>
<p><font color="red">这样的向量不唯一！！！</font></p>
<p><img src="/2022/09/29/%E6%94%AF%E6%8C%81%E5%90%91%E9%87%8F%E6%9C%BA/1.png" alt="1" style="zoom:50%;"></p>
<h2 id="几何间隔geometrical-margin">2.几何间隔(Geometrical Margin)</h2>
<figure>
<img src="/2022/09/29/%E6%94%AF%E6%8C%81%E5%90%91%E9%87%8F%E6%9C%BA/3.png" alt="3">
<figcaption aria-hidden="true">3</figcaption>
</figure>
<p><span class="math inline">\(\pmb{x}_0向量是\pmb{x}在超平面上的投影向量\)</span></p>
<p><span class="math inline">\(y \in \{-1,1\}\)</span>, <span class="math inline">\(\gamma 是向量\pmb{x}到超平面的几何距离\)</span>
<span class="math display">\[
\pmb{x} = \pmb{x}_0 + y\gamma \frac{\pmb{w}}{||\pmb{w}||}
\]</span></p>
<p><span class="math inline">\(\pmb{x}_0在超平面内，于是有\)</span>
<span class="math display">\[
\pmb{w}^T(\pmb{x} - y\gamma \frac{\pmb{w}}{||\pmb{w}||})+b=0
\]</span></p>
<p><span class="math display">\[
\gamma = y \frac{\pmb{w}^T \pmb{x}+b}{||\pmb{w}||}
\]</span></p>
<p><img src="/2022/09/29/%E6%94%AF%E6%8C%81%E5%90%91%E9%87%8F%E6%9C%BA/4.png" alt="4" style="zoom: 67%;"></p>
<p><span class="math inline">\(\gamma\)</span>较大的受到超平面移动的影响较小！！！</p>
<h2 id="maximum-margin-classifier">3.Maximum Margin Classifier</h2>
<p>定义点集的margin是所有点中margin的<font color="red">最小值</font></p>
<p>目标：找到一个超平面以最大化margin <span class="math display">\[
\underset{\pmb{w},b}{max}\gamma = \underset{\pmb{w},b}{max}
\frac{y(\pmb{w}^T \pmb{x}+b)}{||\pmb{w}||}
\]</span></p>
<p><span class="math display">\[
s.t. , \gamma_i \ge \gamma
\]</span></p>
<p>由于<span class="math inline">\(\pmb{x}\)</span>不是在超平面上的点，于是对于同一个超平面<span class="math inline">\(y(\pmb{w}^T
\pmb{x}+b)\)</span>可以无限大，不妨令其为1，不影响结果 <span class="math display">\[
\underset{\pmb{w},b}{max} \frac{y(\pmb{w}^T \pmb{x}+b)}{||\pmb{w}||}
\Rightarrow \underset{\pmb{w},b}{max} \frac{1}{||\pmb{w}||} \Rightarrow
\underset{\pmb{w},b}{min} ||\pmb{w}||
\]</span></p>
<p><span class="math display">\[
\gamma_i = \frac{y_i(\pmb{w}^T \pmb{x}_i+b)}{||\pmb{w}||} \ge \gamma =
\frac{1}{||\pmb{w}||}
\]</span></p>
<p>最终简化问题为(加上系数以及平方不影响最终结果但是方便中间过程求导):
<span class="math display">\[
\underset{\pmb{w},b}{min}
\textcolor{red}{\frac{1}{2}}||\pmb{w}||\textcolor{red}{^2}
\]</span></p>
<p><span class="math display">\[
y_i(\pmb{w}^T \pmb{x}_i+b) \ge 1
\]</span></p>
<p>一个含不等式约束的优化问题</p>
<h2 id="加入惩罚项">4.加入惩罚项</h2>
<p>新的方程: <span class="math display">\[
\underset{\pmb{w},b}{min} {\frac{1}{2}}||\pmb{w}||{^2} \textcolor{red}{+
C\sum_{i=1}^{n}\xi_i}
\]</span></p>
<p><span class="math display">\[
y_i(\pmb{w}^T \pmb{x}_i+b) \ge 1 \textcolor{red}{-\xi_i}
\]</span></p>
<p>其中松弛变量<span class="math inline">\(\xi_i\)</span>: <span class="math display">\[
\xi_i = max[0,1-y_i(\pmb{w}^T \pmb{x}_i+b)]
\]</span> 于是得到</p>
<figure>
<img src="/2022/09/29/%E6%94%AF%E6%8C%81%E5%90%91%E9%87%8F%E6%9C%BA/5.png" alt="5">
<figcaption aria-hidden="true">5</figcaption>
</figure>
<h2 id="一般化的分类器方程">5.一般化的分类器方程</h2>
<p>A General formulation of classifiers： <span class="math display">\[
\underset{f}{min} \{  \sum_{i=1}^{n} \mathscr{l}(f) + \lambda R(f) \}
\]</span></p>
<p><code>Loss function</code>：<span class="math inline">\(\mathscr{l}(f)\)</span></p>
<ul>
<li><code>Square loss (Ordinary regression)</code>：<span class="math inline">\(\mathscr{l}(f) = (1-yf)^2\)</span></li>
<li><code>Logistic loss (Logistic regression)</code>：<span class="math inline">\(\mathscr{l}(f) = log(1 + e^{-yf})\)</span></li>
<li><code>Hinge loss (SVM)</code>：<span class="math inline">\(\mathscr{l}(f) = max[1-yf,0]\)</span></li>
</ul>
<p><code>Regularizer</code>：<span class="math inline">\(R(f)\)</span></p>
<ul>
<li><code>L1-regularizer</code></li>
<li><code>L2-regularizer</code></li>
</ul>
]]></content>
      <categories>
        <category>机器学习</category>
      </categories>
      <tags>
        <tag>机器学习</tag>
      </tags>
  </entry>
  <entry>
    <title>放学后</title>
    <url>/2022/08/27/%E6%94%BE%E5%AD%A6%E5%90%8E/</url>
    <content><![CDATA[<style>
  .markdown-body {
    font-family: Microsoft JhengHei, SimHei;
    font-size: 16px;
  }
</style>
<h1 align="center">
《放学后》
</h1>
<p>1.一口气看完了东野圭吾的《放学后》，作为一篇的悬疑推理小说，不论是情节的组织、细节的设计铺垫方面都是很不错的，也有东野圭吾一贯擅长的反转再反转，结局出人意料，回味前文的细节又觉得在情理之中，读完之后觉得深感震撼。</p>
<p>2.主角前岛是清华女中的一位数学老师，同时担任射箭社的指导老师，他不擅长上课，不擅长和学生互动，只是本分地完成自身的教学工作，被学生们叫做“机器”。就是这样一个不太和他人有交集以及过节的人，一次又一次险些遭人陷害，从天而降的花盆、泳池中的插电板、被人推向飞驰而过的列车……一次又一次险些丧命。这让他很是小心，急迫想要找出陷害他的人。而在他找到答案之前，同为数学老师的村桥老师在更衣室中被人杀害，警方介入调查。一波未平一波又起，在化装表演时，扮成小丑的竹井老师因为喝下道具酒瓶中的液体当场倒地身亡。</p>
<p>3.一切都是因为射箭社的惠子和惠美遭到了村桥和竹井的“视线强暴”，于是萌生了杀人的想法。她们用箭将男更衣室的门抵住，并且在男更衣室与女更衣室间隔的墙上留下痕迹，伪造了一幅凶手从女更衣室逃走的假象，误导警方断案。而在村桥的衣服中也发现了麻生老师的不雅照片，这是村桥老师逼迫麻生老师和他继续维持关系的砝码，后来却成了惠子和惠美威胁麻生协助杀害竹井老师的手段。那些让前岛一次又一次险些丧命的事件原来是她们伪造出来的假象，让警方误认为凶手想杀害的是前岛而不是竹井。</p>
<p>4.故事最后，前岛和妻子通过话后准备回家，却被一个陌生男子用刀捅死，故事戛然而止。委婉地叙述了妻子杀害前岛这一事实，让人大受震撼，但是转念回想前文，前岛和妻子意外有了孩子，前岛执意打掉了孩子，妻子因此也落寞了许久。这样结尾又在情理之中，妻子积怨已久，最终动手杀害了前岛。</p>
<p>5.一些书摘：</p>
<blockquote>
<p>成年人的案件倒不见得会那么复杂。报纸社会新闻版总有各种闹得沸沸扬扬的事件，几乎都能用色、欲、财这三要素来概括</p>
</blockquote>
<blockquote>
<p>但高中女生，就不能拿着几点来套了</p>
<p>对她们来说，最重要的应该是美丽、纯粹、真实的东西，比如友情、爱情，也可能是自己的身体或容貌。很多时候，更抽象的回忆或梦想对她们来说也很重要。反过来说，她们最憎恨企图破坏或从她们手中夺走这些重要东西的人</p>
</blockquote>
<p>6.处于青春期的孩子，自尊心是高于一切的，而成年人们最容易忽视的往往就是自尊心。有意无意间践踏了她们的自尊心却不自知，最终酿成悲剧。小说中还有一位女生叫阳子，她没有直接参与到几次谋杀案中。她母亲很早离世，父亲是位企业家，也无暇顾及女儿。阳子曾邀请前岛一同旅行，前岛最终是放了格子，阳子一人在车站苦苦等待了几个小时。在此之后，阳子也走向了堕落，同小混混飙车麻痹自己。没有人生来就是坏孩子，她们的成长也需要作为成年人的家长、老师的呵护。</p>
<p>7.主角前岛的死也是一出悲剧，忽视了妻子的感受，让负面的情绪在不断积攒，最终上演了悲剧。</p>
]]></content>
      <categories>
        <category>阅读</category>
      </categories>
      <tags>
        <tag>阅读</tag>
      </tags>
  </entry>
  <entry>
    <title>有穷自动机与正则表达式</title>
    <url>/2022/10/19/%E6%9C%89%E7%A9%B7%E8%87%AA%E5%8A%A8%E6%9C%BA%E4%B8%8E%E6%AD%A3%E5%88%99%E8%A1%A8%E8%BE%BE%E5%BC%8F/</url>
    <content><![CDATA[<style> 
    .markdown-body {
      font-family: Microsoft JhengHei, SimHei;
      font-size: 16px;
    }
</style>
<h1 align="center">
有穷自动机与正则表达式
</h1>
<h2 id="定理2.3.1">定理2.3.1</h2>
<p><font color="orange">有穷自动机接受的语言类在下述运算下是封闭的：</font></p>
<p><font color="orange">（a）并</font></p>
<p><font color="orange">（b）连接</font></p>
<p><font color="orange">（c）Kleeene星号</font></p>
<p><font color="orange">（d）补</font></p>
<p><font color="orange">（e）交</font></p>
<hr>
<p>证明：给定两台自动机<span class="math inline">\(M_1\)</span>和<span class="math inline">\(M_2\)</span>构建所需语言的自动机<span class="math inline">\(M\)</span></p>
<p>（a）如下图构建，基本思想为利用非确定性猜想输入在<span class="math inline">\(L(M_1)\)</span>中还是<span class="math inline">\(L(M_2)\)</span>中</p>
<figure>
<img src="/2022/10/19/%E6%9C%89%E7%A9%B7%E8%87%AA%E5%8A%A8%E6%9C%BA%E4%B8%8E%E6%AD%A3%E5%88%99%E8%A1%A8%E8%BE%BE%E5%BC%8F/1.png" alt="1">
<figcaption aria-hidden="true">1</figcaption>
</figure>
<p>（b）基本思想，先模拟<span class="math inline">\(M_1\)</span>，再从<span class="math inline">\(M_1\)</span>的终结状态跳转到<span class="math inline">\(M_2\)</span>的初始状态，随后继续模拟<span class="math inline">\(M_2\)</span>即可</p>
<figure>
<img src="/2022/10/19/%E6%9C%89%E7%A9%B7%E8%87%AA%E5%8A%A8%E6%9C%BA%E4%B8%8E%E6%AD%A3%E5%88%99%E8%A1%A8%E8%BE%BE%E5%BC%8F/2.png" alt="2">
<figcaption aria-hidden="true">2</figcaption>
</figure>
<p>（c）构建<span class="math inline">\(M_1\)</span>中每一个终结状态到<span class="math inline">\(M_1\)</span>初始状态的转移，如此便能多次模拟<span class="math inline">\(M_1\)</span>的运行了</p>
<figure>
<img src="/2022/10/19/%E6%9C%89%E7%A9%B7%E8%87%AA%E5%8A%A8%E6%9C%BA%E4%B8%8E%E6%AD%A3%E5%88%99%E8%A1%A8%E8%BE%BE%E5%BC%8F/3.png" alt="3">
<figcaption aria-hidden="true">3</figcaption>
</figure>
<p>（d）补语言与原来的区别仅仅在于交换终结状态与非终结状态</p>
<p>（e）由于交运算可以写作 <span class="math display">\[
L_1 \cap L_2 = \Sigma^* - ((\Sigma^* - L_1) \cup (\Sigma^* - L_2))
\]</span> 于是由（a）和（d）可以得到交的封闭性</p>
<h2 id="定理2.3.2">定理2.3.2</h2>
<p><font color="orange">一个语言是正则的当且仅当它被有穷自动机接受</font></p>
<hr>
<p>证明：</p>
<p><span class="math inline">\(\Rightarrow\)</span>:</p>
<p>正则语言类是包括空集<span class="math inline">\(\varnothing\)</span>和单元集<span class="math inline">\(\{a\}\)</span>在并、连接和Kleene星号下封闭的最小语言类，其中a是一个符号。于是根据<a href="#定理2.3.1">定理2.3.1</a>的证明可以得出。</p>
<p><span class="math inline">\(\Leftarrow\)</span>:</p>
<p>设<span class="math inline">\(M =
(K,\Sigma,\Delta,s,F)\)</span>是一台有穷自动机，我们需要构造一个正则表达式使得<span class="math inline">\(L(R) = L(M)\)</span></p>
<p>首先将<span class="math inline">\(L(M)\)</span>表示成有穷个简单语言的并</p>
<p>假设<span class="math inline">\(K = \{q_1,\cdots ,q_n\}\)</span> 且
<span class="math inline">\(s = q_1\)</span>.对于<span class="math inline">\(i,j = 1, \cdots , n\)</span>和 <span class="math inline">\(k = 0,\cdots,n\)</span>.<font color="orange">令<span class="math inline">\(R(i,j,k)\)</span>为<span class="math inline">\(\Sigma^*\)</span>中可以使<span class="math inline">\(M\)</span>从状态<span class="math inline">\(q_i\)</span>到<span class="math inline">\(q_j\)</span>且不经过编号大于<span class="math inline">\(k\)</span>的中间状态的所有字符串，两端的状态<span class="math inline">\(q_i\)</span>和<span class="math inline">\(q_j\)</span>可以大于<span class="math inline">\(k\)</span>.</font></p>
<p>于是当<span class="math inline">\(k=n\)</span>时，有 <span class="math display">\[
R(i,j,n) = \{ w \in \Sigma^* : (q_i,w)\vdash^*_M (q_j,e) \}
\]</span> 因此 <span class="math display">\[
L(M) = \bigcup \{ R(i,j,n):q_j \in F \}
\]</span> 关键是要证明所有这些集合<span class="math inline">\(R(i,j,k)\)</span>是正则的，从而<span class="math inline">\(L(M)\)</span>是正则的</p>
<p>对<span class="math inline">\(k\)</span>作归纳，首先考虑<span class="math inline">\(k=0\)</span>的情形，当<span class="math inline">\(i \neq j\)</span>时<span class="math inline">\(R(i,j,k)\)</span>为</p>
<p><span class="math inline">\(\{ a \in \Sigma \cup \{e\} :
(q_i,a,q_j)\in \Delta \}\)</span>，当<span class="math inline">\(i =
j\)</span>时为<span class="math inline">\(\{e\} \cup \{ a \in \Sigma :
(q_i,a,q_i)\in \Delta \}\)</span></p>
<p><font color="orange">这些集合都是有穷的，进而推出是正则的</font></p>
<p>再进行归纳的递推 <span class="math display">\[
R(i,j,k) = R(i,j,k-1) \cup R(i,k,k-1)R(k,k,k-1)^*R(k,j,k-1)
\]</span> 上述递推式表示两种可能</p>
<ul>
<li>从<span class="math inline">\(q_i\)</span>到<span class="math inline">\(q_j\)</span>不经过编号大于<span class="math inline">\(k-1\)</span>的中间状态</li>
<li>从<span class="math inline">\(q_i\)</span>到<span class="math inline">\(q_k\)</span>，再从<span class="math inline">\(q_k\)</span>到<span class="math inline">\(q_k\)</span>若干次，最后从<span class="math inline">\(q_k\)</span>到<span class="math inline">\(q_j\)</span>，每次都不经过编号大于<span class="math inline">\(k-1\)</span>的中间状态</li>
</ul>
<p>于是<span class="math inline">\(R(i,j,k)\)</span>是正则的</p>
<h2 id="例2.3.2">例2.3.2</h2>
<p>构造2-15图中确定型有穷自动机接受的语言的正则表达式，该自动机接受语言
<span class="math display">\[
\{ w \in \{a,b\}^* : w 有 3k+1个b,k\in N \}
\]</span> <img src="/2022/10/19/%E6%9C%89%E7%A9%B7%E8%87%AA%E5%8A%A8%E6%9C%BA%E4%B8%8E%E6%AD%A3%E5%88%99%E8%A1%A8%E8%BE%BE%E5%BC%8F/4.png" alt="4"></p>
<p>解：</p>
<p>直接依据定理2.3.2构建<span class="math inline">\(R(i,j,k)\)</span>会十分繁琐，我们假定两条性质，简化问题</p>
<ul>
<li>自动机有唯一的终结状态，<span class="math inline">\(F =
\{f\}\)</span></li>
<li>没有进入初始状态和离开终结状态的转移</li>
</ul>
<p>基本思路为在原自动机的基础上添加两个状态，随后依次去除原有的所有状态</p>
<figure>
<img src="/2022/10/19/%E6%9C%89%E7%A9%B7%E8%87%AA%E5%8A%A8%E6%9C%BA%E4%B8%8E%E6%AD%A3%E5%88%99%E8%A1%A8%E8%BE%BE%E5%BC%8F/5.png" alt="5">
<figcaption aria-hidden="true">5</figcaption>
</figure>
<p>于是得到结果语言的正则表达式为 <span class="math display">\[
R = R(4,5,5) = R(4,5,3) = a^*b(a\cup ba^*ba^*b)^*
\]</span></p>
]]></content>
      <categories>
        <category>计算理论</category>
      </categories>
      <tags>
        <tag>计算理论</tag>
      </tags>
  </entry>
  <entry>
    <title>正则语言与非正则语言</title>
    <url>/2022/10/19/%E6%AD%A3%E5%88%99%E8%AF%AD%E8%A8%80%E4%B8%8E%E9%9D%9E%E6%AD%A3%E5%88%99%E8%AF%AD%E8%A8%80/</url>
    <content><![CDATA[<style> 
    .markdown-body {
      font-family: Microsoft JhengHei, SimHei;
      font-size: 16px;
    }
</style>
<h1 align="center">
正则语言与非正则语言
</h1>
<h2 id="定理2.4.1">定理2.4.1</h2>
<p><font color="orange">设<span class="math inline">\(L\)</span>是一个正则语言，则存在正整数<span class="math inline">\(n \ge 1\)</span>使得任一字符串<span class="math inline">\(w \in L\)</span></font></p>
<p><font color="orange">只要<span class="math inline">\(|w| \ge
n\)</span>就可以写成<span class="math inline">\(w =
xyz\)</span>,</font></p>
<p><font color="orange">其中<span class="math inline">\(y \neq
e\)</span>,<span class="math inline">\(|xy| \le
n\)</span>且对每一个<span class="math inline">\(i \ge 0\)</span>,<span class="math inline">\(xy^iz \in L\)</span>.</font></p>
<hr>
<p>证明：</p>
<p>由于<span class="math inline">\(L\)</span>是正则的,它能够被一台确定型有穷自动机<span class="math inline">\(M\)</span>接受.</p>
<p>设<span class="math inline">\(M\)</span>有<span class="math inline">\(n\)</span>个状态,<span class="math inline">\(w \in
L\)</span>是一个长度大于等于<span class="math inline">\(n\)</span>的字符串.考虑<span class="math inline">\(M\)</span>的前<span class="math inline">\(n\)</span>步计算： <span class="math display">\[
(q_0,w_1 w_2 \cdots w_n) \vdash_M (q_1,w_2 \cdots w_n) \vdash_M \cdots
\vdash_M(q_n , e)
\]</span> 由于自动机只有<span class="math inline">\(n\)</span>个状态,但是却有<span class="math inline">\(n+1\)</span>个格局<span class="math inline">\((q_i,w_{i+1}\cdots
w_n)\)</span>,根据<font color="red">鸽巢原理</font>,必然存在i和j<span class="math inline">\(0 \le i &lt; j \le n\)</span>使得<span class="math inline">\(q_i = q_j\)</span> .即字符串<span class="math inline">\(y = w_{i+1} \cdots w_n\)</span>从状态<span class="math inline">\(q_i\)</span>回到本身<span class="math inline">\(q_i\)</span>.</p>
<p>于是删去<span class="math inline">\(y\)</span>或者重复任意次<span class="math inline">\(y\)</span>都不影响字符串被<span class="math inline">\(M\)</span>接受</p>
<h2 id="例2.4.2">例2.4.2</h2>
<p>语言<span class="math inline">\(L = \{a^i b^i :i \ge 0
\}\)</span>不是正则的.</p>
<p>现假设<span class="math inline">\(L\)</span>是正则的,运用上述定理,<span class="math inline">\(w = a^n b^n \in L\)</span> .</p>
<p>于是<span class="math inline">\(y = a^i\)</span>,若<span class="math inline">\(L\)</span>是正则的,那么删去<span class="math inline">\(y\)</span>后的语言应当仍然被自动机接受,仍然包含于语言<span class="math inline">\(L\)</span>中.</p>
<p>但是,<span class="math inline">\(xz = a^{n-i} b^{n} \notin
L\)</span>,矛盾.</p>
<h2 id="例2.4.3">例2.4.3</h2>
<p>语言<span class="math inline">\(L = \{a^n :n是素数
\}\)</span>不是正则的.</p>
<p>同理,我们先假设<span class="math inline">\(L\)</span>是正则的,运用定理</p>
<p>令<span class="math inline">\(x = a^p, y = a^q , z =
a^r\)</span>,其中<span class="math inline">\(p,r \ge 0\)</span>且<span class="math inline">\(q &gt; 0\)</span>.</p>
<p>由于<span class="math inline">\(xy^nz \in L\)</span>对于任意<span class="math inline">\(n \ge 0\)</span>.那么<span class="math inline">\(p+nq+r\)</span>也是素数</p>
<p>取<span class="math inline">\(n = p + 2q +r +2\)</span>,</p>
<p>那么<span class="math inline">\(p+nq+r = (q+1) \cdot
(p+2q+r)\)</span>,</p>
<p>可见并非素数,产生矛盾</p>
]]></content>
      <categories>
        <category>计算理论</category>
      </categories>
      <tags>
        <tag>计算理论</tag>
      </tags>
  </entry>
  <entry>
    <title>白夜行</title>
    <url>/2022/09/04/%E7%99%BD%E5%A4%9C%E8%A1%8C/</url>
    <content><![CDATA[<style>
  .markdown-body {
    font-family: Microsoft JhengHei, SimHei;
    font-size: 16px;
  }
</style>
<h1 align="center">
《白夜行》
</h1>
<ol type="1">
<li><p>雪穗，生活在一个贫苦的单亲家庭，在母亲的策划下，即使还是个上小学的幼女却被迫出卖身体。</p></li>
<li><p>亮司，多次目睹母亲和雇佣的店员偷腥，甚至发现了父亲玷污自己的好朋友雪穗。</p></li>
<li><p>两人都有着极其不幸的童年，他们一同杀害了亮司的父亲，也间接谋害了雪穗的母亲，从此，雪穗投靠了亲戚步步向上走，而亮司也离开了母亲，一直生活在阴暗的世界里，帮助雪穗。</p></li>
<li><p>他们谋划了一起又一起犯罪事件，所有影响到雪穗人生的人物无一例外都遭到了他们的毒手。</p></li>
<li><p>最终他们都变成了自己最讨厌的模样：在雪穗的谋划下，自己女儿遭到了强暴，亮司正是强暴幼女的凶手。</p></li>
<li><p>不幸的童年造成了层出不穷的悲剧，但这并不是他们作恶多端的借口，他们不值得同情，那些他们手下的受害者又由谁去同情</p></li>
<li><blockquote>
<p>"我的人生就像在白夜里走路"</p>
</blockquote></li>
<li><blockquote>
<p>"一天当中，有太阳升起的时候，也有下沉的时候。人生也一样，有白天和黑夜，只是不会像真正的太阳那样，有定时的日出和日落。看个人，有些人一辈子都活在太阳的照耀下，也有些人不得不一直活在漆黑的深夜里。人害怕的，就是本来一直存在的太阳落下不再升起，也就是非常害怕原本照在身上的光芒消失"</p>
</blockquote></li>
</ol>
]]></content>
      <categories>
        <category>阅读</category>
      </categories>
      <tags>
        <tag>阅读</tag>
      </tags>
  </entry>
  <entry>
    <title>神经网络</title>
    <url>/2022/09/20/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/</url>
    <content><![CDATA[<style> 
    .markdown-body {
      font-family: Microsoft JhengHei, SimHei;
      font-size: 16px;
    }
</style>
<h1 align="center">
神经网络
</h1>
<h2 id="监督学习supervised-learning">1.监督学习(Supervised
Learning)</h2>
<p>Learning from <font color="red">experience</font>(training data), and
build <font color="red">model</font> to <font color="red">predict</font> the
future</p>
<p>步骤：</p>
<ul>
<li>Collect training samples</li>
<li><font color="red">Define features</font></li>
<li><font color="red">Design &amp; Train Model</font></li>
<li>Make prediction</li>
</ul>
<h2 id="感知机perceptron">2.感知机(Perceptron)</h2>
<figure>
<img src="/2022/09/20/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/1.png" alt="1">
<figcaption aria-hidden="true">1</figcaption>
</figure>
<p>感知机用于对数据进行二分类，输出只有 1 和
-1，分别代表两种数据类别</p>
<p>对加权求和后的结果应用一个符号函数，若输入正数则输出1，否则输出-1</p>
<p>感知机模型的函数定义： <span class="math display">\[
f(x) = sign(\pmb{w}\pmb{x}+b)
\]</span> 其中： <span class="math display">\[
sign(x) = \left\{\begin{matrix} 1,x&gt;0 \\
-1,x&lt;0 \end{matrix}\right.
\]</span></p>
<p><img src="/2022/09/20/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/2.png" alt="2" style="zoom:50%;"></p>
<p>定义损失函数：</p>
<p>我们希望两边的数据点到超平面的距离总和越小越好</p>
<p>距离公式：(<span class="math inline">\(\pmb{w}\)</span>是超平面的法向量，该公式可以理解为$
cos$，即为点到平面距离) <span class="math display">\[
d = \frac{1}{||\pmb{w}||} |\pmb{w}\pmb{x}|
\]</span></p>
<p>ps：为什么<span class="math inline">\(\pmb{w}\)</span>是超平面<span class="math inline">\(\pmb{w}\pmb{x}=0\)</span>的法向量？</p>
<p>设<span class="math inline">\(\pmb{x_1}\)</span> ,<span class="math inline">\(\pmb{x_2}\)</span>是超平面内的两个不同向量 <span class="math display">\[
\pmb{w}\pmb{x_1}=0
\]</span> <span class="math display">\[
\pmb{w}\pmb{x_2}=0
\]</span></p>
<p>相消后得 <span class="math display">\[
\pmb{w}(\pmb{x_1}-\pmb{x_2})=0
\]</span> 由于<span class="math inline">\(\pmb{x_1}-\pmb{x_2}\)</span>是超平面内的向量，于是<span class="math inline">\(\pmb{w}\)</span>是超平面的法向量</p>
<p>对于每一个误分类的点，均有： <span class="math display">\[
-y_i(\pmb{w}\pmb{x}_i+b) &gt; 0
\]</span> 可以借此去掉距离公式中的绝对值</p>
<p>ps：为什么不考虑<span class="math inline">\(\frac{1}{||\pmb{w}||}\)</span></p>
<p>因为感知机由最终的正负号来决定结果，去掉此部分不影响结果，且便于后续的求导。</p>
<p>最终得到损失函数： <span class="math display">\[
J(\pmb{w}) = -\sum_{i}\pmb{w}^T\pmb{x}_iy_i
\]</span> 求解梯度： <span class="math display">\[
\nabla J =-\sum_{i}\pmb{x}_iy_i
\]</span> 于是得到更新参数策略： <span class="math display">\[
\pmb{w}(k+1) = \pmb{w}(k) + \eta(k)\sum_{i}\pmb{x}_iy_i
\]</span></p>
<h2 id="deep-learning发展中遇到的问题">3.Deep
Learning发展中遇到的问题</h2>
<ul>
<li>很难训练一个深层次的网络(梯度消失问题)</li>
<li>计算资源耗费巨大</li>
<li>当时数据集较小，没有训练深度网络的需求</li>
</ul>
<h2 id="反向传播算法backpropagation-algorithm">4.反向传播算法(Backpropagation
Algorithm)</h2>
<p>过程如下：</p>
<figure>
<img src="/2022/09/20/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/5.png" alt="5">
<figcaption aria-hidden="true">5</figcaption>
</figure>
<h2 id="激活函数activation-function">5.激活函数(Activation
Function)</h2>
<p>一些特征与要求：</p>
<ul>
<li>必须是<font color="red">非线性</font>的而且<font color="red">有上下界</font>的</li>
<li>激活函数及其导数必须是<font color="red">连续的、光滑的、单调的</font></li>
<li>根据问题有针对性地选择</li>
</ul>
<blockquote>
<p><span class="math inline">\(sigmoid \space function \space(logistic
\space function)\)</span></p>
</blockquote>
<p><span class="math display">\[
\sigma(x) = \frac{1}{1+e^{-x}}
\]</span></p>
<p><img src="/2022/09/20/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/3.png" alt="3" style="zoom:50%;"></p>
<blockquote>
<p><span class="math inline">\(tanh \space function\)</span></p>
</blockquote>
<p><span class="math display">\[
t(x) = \frac{e^x - e^{-x}}{e^{x}+e^{-x}} \\
t(x) = 2 \sigma(2x)-1
\]</span></p>
<p><img src="/2022/09/20/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/4.png" alt="4" style="zoom:50%;"></p>
<p>以tanh函数为例，其一阶导数形如：</p>
<figure>
<img src="/2022/09/20/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/6.png" alt="6">
<figcaption aria-hidden="true">6</figcaption>
</figure>
<p><strong><font color="red">可见其取值均小于1</font></strong></p>
<p><strong>反向传播时会出现<font color="red">梯度消失</font>问题！！！</strong></p>
<figure>
<img src="/2022/09/20/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/7.png" alt="7">
<figcaption aria-hidden="true">7</figcaption>
</figure>
<p>直到2011年，ReLU被提出</p>
<blockquote>
<p><span class="math inline">\(ReLU \space function\)</span></p>
</blockquote>
<p><span class="math display">\[
ReLU(x) = max(0,x)
\]</span></p>
<figure>
<img src="/2022/09/20/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/8.png" alt="8">
<figcaption aria-hidden="true">8</figcaption>
</figure>
<p>ReLU的优点：</p>
<ul>
<li>统计上有一半的神经元是静默的，ReLU更加<strong>贴合生物学规律</strong></li>
<li>ReLU相较于sigmoid通常具有<strong>更好的表现</strong>,且<strong>对预训练不敏感</strong></li>
<li><strong>计算资源的消耗更少</strong></li>
<li>ReLU的导数只能为0或1，<strong>不必担心梯度消失问题</strong></li>
<li>用<strong>更少</strong>激活的神经元就能灵活而稳定地表示特征</li>
</ul>
<h2 id="dropout-算法">6.Dropout 算法</h2>
<p>每个神经元以一定概率(e.g. p =
0.5)被激活，以减小大型神经网络的训练难度</p>
<figure>
<img src="/2022/09/20/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/9.png" alt="9">
<figcaption aria-hidden="true">9</figcaption>
</figure>
<h2 id="卷积神经网络cnnconvolutional-neural-networks">7.卷积神经网络(CNN,Convolutional
Neural Networks)</h2>
<p>图片中有大量的像素点</p>
<p>若是采用全连接神经网络将会需要巨量的参数</p>
<p><img src="/2022/09/20/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/10.png" alt="10" style="zoom:50%;"></p>
<p>图像具有很好的<strong>局部性</strong>(在时间上和空间上相近的像素高度相关)</p>
<p>CNN只连接一块一块的<strong>局部感受野</strong>，感受野中的像素<strong>共享权重</strong></p>
<p><img src="/2022/09/20/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/11.png" alt="11" style="zoom:50%;"></p>
<p>在数学上，卷积(Convolution)能够很好的反映两个函数之间的相似性 <span class="math display">\[
(f*g)(t) = \int_{-\infty}^{\infty}f(\tau)g(t-\tau)d\tau
\]</span></p>
<p>对图像的卷积操作(利用卷积核)</p>
<p><img src="/2022/09/20/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/12.png" alt="12" style="zoom:50%;"></p>
<p>不同的卷积核会带来不同的效果</p>
<figure>
<img src="/2022/09/20/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/13.png" alt="13">
<figcaption aria-hidden="true">13</figcaption>
</figure>
<p>CNN的一般结构</p>
<figure>
<img src="/2022/09/20/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/14.png" alt="14">
<figcaption aria-hidden="true">14</figcaption>
</figure>
<p><strong>有时可以没有池化层和全连接层</strong></p>
<p>池化(Pooling)</p>
<p>举个例子,MAX POOLING</p>
<figure>
<img src="/2022/09/20/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/15.png" alt="15">
<figcaption aria-hidden="true">15</figcaption>
</figure>
<p>取每个区域内的最大值作为新的值</p>
]]></content>
      <categories>
        <category>机器学习</category>
      </categories>
      <tags>
        <tag>机器学习</tag>
      </tags>
  </entry>
  <entry>
    <title>线性回归</title>
    <url>/2022/09/19/%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92-1/</url>
    <content><![CDATA[<style> 
    .markdown-body {
      font-family: Microsoft JhengHei, SimHei;
      font-size: 16px;
    }
</style>
<h1 align="center">
线性回归
</h1>
<h2 id="分类classification与回归regression">1.分类(Classification)与回归(Regression)</h2>
<p>共同点：</p>
<ul>
<li>学习一个从<code>输入x</code>到<code>输出y</code>的<font color="red">映射</font></li>
</ul>
<p>分类：</p>
<ul>
<li>y是一个分类变量</li>
</ul>
<p>回归：</p>
<ul>
<li>y是一个实际的数值</li>
</ul>
<h2 id="线性模型linear-model">2.线性模型(Linear Model)</h2>
<p>Linear Function: <span class="math display">\[
f(x) = \pmb{w}^T\pmb{x} + b
\]</span></p>
<blockquote>
<p><span class="math inline">\(\pmb{x} = [x_1,x_2,...,x_d]^T \in
R^d\)</span></p>
<p><span class="math inline">\(\pmb{w} = [w_1,w_2,...,w_d]^T \in
R^d\)</span></p>
</blockquote>
<p>进一步简化表示为： <span class="math display">\[
f(x) = \pmb{w}^T\pmb{x}
\]</span></p>
<blockquote>
<p><span class="math inline">\(\pmb{x} = [x_1,x_2,...,x_d,1]^T \in
R^{d+1}\)</span></p>
<p><span class="math inline">\(\pmb{w} = [w_1,w_2,...,w_d,b]^T \in
R^{d+1}\)</span></p>
</blockquote>
<h2 id="多项式曲线拟合polynomial-curve-fitting">3.多项式曲线拟合(Polynomial
Curve Fitting)</h2>
<p>用多项式去拟合若干给定的数据点</p>
<figure>
<img src="/2022/09/19/%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92-1/1.png" alt="1">
<figcaption aria-hidden="true">1</figcaption>
</figure>
<p><span class="math display">\[
f(x,\pmb{w}) = w_0 + w_1x + w_2x + ... +w_Mx^M = \sum_{j=0}^{M}w_jx^j
\]</span></p>
<p>一些例子:</p>
<p><span class="math inline">\(0^{th} Order Polynomial\)</span></p>
<figure>
<img src="/2022/09/19/%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92-1/2.png" alt="2">
<figcaption aria-hidden="true">2</figcaption>
</figure>
<p><span class="math inline">\(1^{st} Order Polynomial\)</span></p>
<figure>
<img src="/2022/09/19/%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92-1/3.png" alt="3">
<figcaption aria-hidden="true">3</figcaption>
</figure>
<p><span class="math inline">\(3^{rd} Order Polynomial\)</span></p>
<figure>
<img src="/2022/09/19/%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92-1/4.png" alt="4">
<figcaption aria-hidden="true">4</figcaption>
</figure>
<p>多项式拟合是一种线性模型</p>
<blockquote>
<p><span class="math inline">\(\pmb{x} =
[1,x,x^2,...,x^M]^T\)</span></p>
<p><span class="math inline">\(\pmb{w} =
[w_1,w_2,...,w_M]^T\)</span></p>
<p><span class="math inline">\(f(x,\pmb{w}) =
\pmb{w}^T\pmb{x}\)</span></p>
</blockquote>
<h2 id="损失函数error-function">4.损失函数(Error Function)</h2>
<figure>
<img src="/2022/09/19/%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92-1/5.png" alt="5">
<figcaption aria-hidden="true">5</figcaption>
</figure>
<blockquote>
<p>空心点为训练数据(training data)</p>
<p>实线为训练所得函数 <span class="math inline">\(f(x) = y\)</span></p>
</blockquote>
<p>均方差损失函数(MSE,Mean Square Error) <span class="math display">\[
MSE(\pmb{w})=\frac{1}{n}\sum_{i=1}^{n}(y_i-f(x_i,\pmb{w}))^2
\]</span> 用来评价训练所得函数与训练数据的吻合程度</p>
<p>训练目标是<font color="red">最小化</font>均方差损失(n可以看作一个常数暂时抛开不看)</p>
<p>化简得： <span class="math display">\[
J_n = \sum_{i=1}^{n}(y_i - \pmb{w}^T\pmb{x}_i)^2
\]</span> 使用矩阵相关记号:</p>
<blockquote>
<p><span class="math inline">\(X =
[\pmb{x}_1,...,\pmb{x}_n]\)</span></p>
<p><span class="math inline">\(y =
[\pmb{y}_1,...,\pmb{y}_n]^T\)</span></p>
</blockquote>
<p><span class="math display">\[
J_n(\pmb{w})=(\pmb{y}-X^T\pmb{w})^T(\pmb{y}-X^T\pmb{w})
\]</span></p>
<p>梯度为0时损失值下降最快</p>
<p>先计算梯度： <span class="math display">\[
\nabla J_n = -2X(\pmb{y}-X^T\pmb{w})
\]</span> 令梯度为0： <span class="math display">\[
XX^T \pmb{w} = X \pmb{y} \\
\pmb{w} = (XX^T)^{-1}X\pmb{y}
\]</span> 于是得到了参数<span class="math inline">\(\pmb{w}\)</span>的修正后的数值</p>
<h2 id="统计模型statistical-model">5.统计模型(Statistical Model)</h2>
<p>给定一个生成模型: <span class="math display">\[
y = f(\pmb{x},\pmb{w}) + \epsilon
\]</span> 假设: <span class="math display">\[
\epsilon  \sim N(0,\sigma^2)
\]</span> 于是: <span class="math display">\[
p(y|\pmb{x},\pmb{w},\sigma) = \frac{1}{\sigma \sqrt{2\pi}}
e^{-\frac{1}{2\sigma^2}}(y-f(\pmb{x},\pmb{w}))^2
\]</span></p>
<p>先介绍一下argmax函数</p>
<blockquote>
<p>有一个函数 <span class="math inline">\(y = f(x)\)</span> 时</p>
<p>若有 <span class="math inline">\(x_0 = argmax(f(x))\)</span></p>
<p>则表示当 <span class="math inline">\(x = x_0\)</span> 时，函数 <span class="math inline">\(f(x)\)</span> 取到最大值</p>
</blockquote>
<p>极大似然估计(Maximum Likelihood Estimation) <span class="math display">\[
L(\pmb{D},\pmb{w},\sigma)=\prod_{i=1}^{n}
p(y_i|\pmb{x}_i,\pmb{w},\sigma) \\
\pmb{w}^* = argmax \prod_{i=1}^{n} p(y_i|\pmb{x}_i,\pmb{w},\sigma)
\]</span> 由于log函数单调不影响结果,于是取对数为Log-likelihood <span class="math display">\[
l(\pmb{D},\pmb{w},\sigma) = log(L(\pmb{D},\pmb{w},\sigma)) =
log\prod_{i=1}^{n} p(y_i|\pmb{x}_i,\pmb{w},\sigma) \\
=\sum_{i=1}^{n}log \space p(y_i|\pmb{x}_i,\pmb{w},\sigma)\\
= -\frac{1}{2\sigma^2}\sum_{i=1}^{n}(y-f(\pmb{x,\pmb{w}}))^2+c(\sigma)
\]</span> 忽略常数后得到: <span class="math display">\[
RSS(f) = \sum_{i=1}^{n}(y_i-f(\pmb{x}_i,\pmb{w}))^2
\]</span></p>
<p><strong>线性回归模型 <span class="math inline">\(\Leftrightarrow\)</span>
具有高斯噪声的生成模型的极大似然估计</strong></p>
<hr>
<p>为了解决模型过拟合(Over-fitting)的问题，在原来基础上加入惩罚项，参数越多(模型越复杂)惩罚越大。</p>
<hr>
<h2 id="岭回归ridge-regressionl2正则化">6.岭回归(Ridge
Regression)(L2正则化)</h2>
<p><span class="math display">\[
w^* = argmin\sum_{i=1}^{n}(y_i-\pmb{x}_i^T\pmb{w})^2  \textcolor{red}{ +
\lambda\sum^{p}_{j=1}w_j^2}
\]</span></p>
<p>其对参数的限制方式可以表示为: <span class="math display">\[
\textcolor{red}{\sum^{p}_{j=1}w_j^2 \le t}
\]</span></p>
<p>经过矩阵表示、梯度计算、化简等步骤后得到: <span class="math display">\[
\pmb{w}^* = (XX^T+\lambda\pmb{I})^{-1}X\pmb{y}
\]</span> 可以人为调节<span class="math inline">\(\lambda\)</span>的大小来得到更好效果的模型参数</p>
<h2 id="lasso回归least-absolute-selection-and-shrinkage-operatorl1正则化">7.LASSO回归(Least
Absolute Selection and Shrinkage Operator)(L1正则化)</h2>
<p><span class="math display">\[
w^* = argmin\sum_{i=1}^{n}(y_i-\pmb{x}_i^T\pmb{w})^2  \textcolor{red}{ +
\lambda\sum^{p}_{j=1}|w_j|}
\]</span></p>
<p>其对参数的限制方式为: <span class="math display">\[
\textcolor{red}{\sum^{p}_{j=1}|w_j| \le t}
\]</span></p>
]]></content>
      <categories>
        <category>机器学习</category>
      </categories>
      <tags>
        <tag>机器学习</tag>
      </tags>
  </entry>
  <entry>
    <title>聚类</title>
    <url>/2022/09/28/%E8%81%9A%E7%B1%BB/</url>
    <content><![CDATA[<style> 
    .markdown-body {
      font-family: Microsoft JhengHei, SimHei;
      font-size: 16px;
    }
</style>
<h1 align="center">
聚类
</h1>
<h2 id="简介">1.简介</h2>
<p><code>Cluster</code>: A collection of data objects</p>
<p><code>Clustering</code>: <font color="red">Finding similarities</font>
between data according to the characteristics found in the data and
<font color="red">grouping</font> similar data objects into clusters</p>
<p>采用的方法：<strong>Unsupervised Learning</strong></p>
<p>一些典型的应用：</p>
<ul>
<li>作为独立的工具，用作图像分割、新闻分类等</li>
<li>作为其他算法的预处理步骤</li>
</ul>
<h2 id="k-means算法">2.K-Means算法</h2>
<p>对于给定的K，该算法步骤如下：</p>
<ul>
<li><p>随机选取<span class="math inline">\(K\)</span>个数据点作为每个类别的聚类中心<span class="math inline">\(\mu_k\)</span></p></li>
<li><p>对每一个点计算到每一个聚类中心的距离，并将其归类于最近的一个聚类中心同种类别
<span class="math display">\[
z_i = arg \space \underset{k}{min} ||\pmb{x}_i - \pmb{\mu} _k||^2
\]</span></p></li>
<li><p>对于每一个聚类依据如下公式重新计算聚类中心(即质心) <span class="math display">\[
\mu_k = \frac{1}{N_k} \sum_{i=1}^{N_k}\pmb{x}_i^{(k)}
\]</span></p></li>
<li><p>重复上述过程直到收敛</p></li>
</ul>
<p>一些细节：</p>
<blockquote>
<p>初始的<span class="math inline">\(\mu_k\)</span>不一定需要选取真实的数据点</p>
</blockquote>
<blockquote>
<p>可能会有空的聚类出现</p>
</blockquote>
<blockquote>
<p>算法时间复杂度<span class="math inline">\(O(tNKd)\)</span>,其中
t为递归次数，d为点的维数</p>
</blockquote>
<p><img src="/2022/09/28/%E8%81%9A%E7%B1%BB/1.png" alt="1" style="zoom:50%;"></p>
<p>损失函数： <span class="math display">\[
\mathcal{L}_{TSD}(\pmb{z},\pmb{\mu}) = \sum_{i=1}^{N}||\pmb{x}_i -
\pmb{\mu}_{z_i}||^2
\]</span> 贪心算法最终得到的是一个<font color="red">局部最优解</font></p>
<h2 id="k-medoids算法pam">3.K-Medoids算法(PAM)</h2>
<p>由于K-Means算法容易受到个别<font color="red">极端点</font>的影响，于是加以改进</p>
<p>不再选用质心作为中心点，而选取同一聚类中其他所有点到该点距离和最小的点为中心点
<span class="math display">\[
\pmb{\mu} = arg \space \underset{\pmb{x}_k}{min}\sum_j ||\pmb{x}_j -
\pmb{x}_k||^2
\]</span></p>
<h2 id="gaussian-mixture-modelgmm">4.Gaussian Mixture Model(GMM)</h2>
<p><img src="/2022/09/28/%E8%81%9A%E7%B1%BB/3.png" alt="3" style="zoom:67%;"> <span class="math display">\[
p(\pmb{x};\pmb{\Theta})
=  \sum_{k=1}^{K}p(k)p(\pmb{x}|k)=\sum_{k=1}^{K}\pi_kp_k(\pmb{x};\pmb{\theta_k})
\]</span></p>
<p><span class="math display">\[
其中\pi_k是概率p(k),\sum_{k=1}^{K}\pi_k = 1
\]</span></p>
<p><span class="math display">\[
其中p_k(\pmb{x};\pmb{\theta_k})即为p(\pmb{x}|k),符合多维正态\mathcal{N}(\pmb{x};\pmb{\mu}_k,\pmb{\Sigma}_k)
\]</span></p>
<p>log-likelihood function: <span class="math display">\[
log \prod_{i=1}^{N}p(\pmb{x}^{(i)};\Theta) =
\sum_{i=1}^{N}log(\sum_{k=1}^{K}\pi_k
\mathcal{N}(\pmb{x}^{(i)};\pmb{\mu}_k,\pmb{\Sigma}_k))
\]</span></p>
<p>需要估计的参数有：<span class="math inline">\(\pi_k,\pmb{\mu}_k,\pmb{\Sigma}_k\)</span></p>
<h2 id="expectation-maximization算法em">5.Expectation
Maximization算法(EM)</h2>
<p>凸函数(Convex Functions)： <span class="math display">\[
f(\theta x + (1-\theta)y) \le \theta f(x) + (1-\theta ) f(y)
\]</span> <img src="/2022/09/28/%E8%81%9A%E7%B1%BB/4.png" alt="4" style="zoom:50%;"></p>
<p>Jensen’s inequality: <span class="math display">\[
f(\sum_{i=1}^{n}\lambda_i x_i) \le \sum_{i=1}^{n}\lambda_if(x_i) \space
\space \space \space \lambda_i \ge 0, \sum_i \lambda_i = 1
\]</span></p>
<p><span class="math display">\[
f(E(X)) \le E[f(X)]
\]</span></p>
<p>EM algorithm</p>
<p>每次EM算法的迭代包含两个步骤<code>Expectation-step</code> 和
<code>Maximization-step</code></p>
<ol type="1">
<li>E步骤：根据参数的假设值，给出未知变量的期望估计，应用于缺失值。</li>
<li>M步骤：根据未知变量的估计值，给出当前的参数的极大似然估计。</li>
</ol>
<p>根据图直观理解：</p>
<p><img src="/2022/09/28/%E8%81%9A%E7%B1%BB/5.png" alt="5" style="zoom: 50%;"></p>
<p>E: 根据参数<span class="math inline">\(\theta_1\)</span>给出估计，即图中小的凹函数</p>
<p>M: 进行极大似然估计，找到该函数的最大值处对应的参数<span class="math inline">\(\theta_2\)</span></p>
<p>不断进行迭代找到最优解</p>
]]></content>
      <categories>
        <category>机器学习</category>
      </categories>
      <tags>
        <tag>机器学习</tag>
      </tags>
  </entry>
  <entry>
    <title>降维</title>
    <url>/2022/10/12/%E9%99%8D%E7%BB%B4/</url>
    <content><![CDATA[<style> 
    .markdown-body {
      font-family: Microsoft JhengHei, SimHei;
      font-size: 16px;
    }
</style>
<h1 align="center">
降维
</h1>
<h2 id="特征表示">1.特征表示</h2>
<p>对于所有机器学习任务，不论是监督学习还是无监督学习，我们都需要参数<span class="math inline">\(\pmb{x}\)</span></p>
<p>更好的参数表达可以让学习更加简单</p>
<p><span class="math inline">\(\pmb{x}\)</span>应当包含相关的特征，包含尽可能多的特征</p>
<p>为了让学习更加简便高效，我们对变量<span class="math inline">\(\pmb{x}\)</span>进行降维操作</p>
<h2 id="什么是降维dimensionality-reductiondr">2.什么是降维(Dimensionality
Reduction,DR)</h2>
<p>问题抽象为——将<span class="math inline">\(\pmb{x}\)</span>
映射到<span class="math inline">\(\pmb{z}\)</span></p>
<p>其中<span class="math inline">\(\pmb{x}\)</span>是原始的表示，通常具有较高的维度</p>
<p>变换后得到的<span class="math inline">\(\pmb{z}\)</span>
<font color="orange">通常</font>比<span class="math inline">\(\pmb{x}\)</span>具有更低的维度</p>
<h2 id="降维方式线性与非线性">3.降维方式(线性与非线性)</h2>
<p>降维过程通用表示 <span class="math display">\[
\mathcal{F}(\pmb{x} \in R^p) = \pmb{z} \in R^d
\]</span> 其中<span class="math inline">\(\mathcal{F}\)</span>的作用是将<span class="math inline">\(p\)</span>维向量映射到<span class="math inline">\(d\)</span>维上</p>
<p>对<span class="math inline">\(\mathcal{F}\)</span>函数可以进一步分解</p>
<p><span class="math inline">\(f_1(\pmb{x}) = z_1\)</span> <span class="math inline">\(f_2(\pmb{x}) = z_2\)</span> <span class="math inline">\(f_d(\pmb{x}) = z_d\)</span></p>
<p>其中的每个小<span class="math inline">\(f\)</span>函数都是将<span class="math inline">\(p\)</span>维向量映射到<span class="math inline">\(1\)</span>维上</p>
<p>如果<span class="math inline">\(f\)</span>是线性的，降维过程可以借用矩阵表示：</p>
<p><span class="math inline">\(\pmb{a}_1^T \pmb{x} = z_1\)</span> ...
<span class="math inline">\(\pmb{a}_i^T \pmb{x} = z_i\)</span></p>
<p><span class="math inline">\(A \triangleq [\pmb{a}_1 ,...,
\pmb{a}_d]\)</span> <span class="math inline">\((A \in
\mathcal{R}^{p\times d})\)</span> <span class="math inline">\(A^T
\pmb{x} = \pmb{z}\)</span></p>
<h2 id="特征提取与特征选择">4.特征提取与特征选择</h2>
<p>特征选择(Feature Selection)：</p>
<blockquote>
<p>从p维的原向量中选择一个d维的子集向量作为结果</p>
</blockquote>
<p><span class="math inline">\(A \in [0,1]^{p \times
d}\)</span>,矩阵的每一列有且仅有一个1</p>
<p>特征提取(Feature Extraction)：</p>
<blockquote>
<p>对原来p维的向量应用线性或非线性的变换得到一个新的d维向量</p>
</blockquote>
<p><span class="math inline">\(A \in \mathcal{R}^{p \times
d}\)</span></p>
<h2 id="降维算法">5.降维算法</h2>
<p>无监督学习：</p>
<ul>
<li>主成分分析(Principal Component Analysis, PCA)</li>
</ul>
<p>监督学习：</p>
<ul>
<li>线性判别分析(Linear Discriminant Analysis, LDA)</li>
</ul>
<p>半监督学习：</p>
<ul>
<li>半监督判别分析(Semi-supervised Discriminant Analysis, SDA)</li>
</ul>
<hr>
<p>线性：</p>
<ul>
<li>主成分分析(Principal Component Analysis, PCA)</li>
<li>线性判别分析(Linear Discriminant Analysis, LDA)</li>
<li>局部保留投影(Locality Preserving Projections, LPP)</li>
<li>基于图的降维方法</li>
</ul>
<p>非线性：</p>
<ul>
<li>“核化”</li>
<li>流形学习(Manifold Learning)
<ul>
<li>ISOMAP</li>
<li>Locally Linear Embedding</li>
<li>Laplacian Eigenmap</li>
</ul></li>
</ul>
<hr>
<h2 id="主成分分析pca">6.主成分分析(PCA)</h2>
<p>定义主成分的第一个分量 <span class="math display">\[
z_i^{(1)} = \pmb{a}_1^T \pmb{x}_i, \; \; \; \;i =1,...,n
\]</span> 使得<span class="math inline">\(\textcolor{red}{\mathcal{var}(z^{(1)})}\)</span>最大</p>
<p><span class="math display">\[
\begin{aligned}
var(z^{(1)}) &amp;= E((z^{(1)} - \overline{z}^{(1)})^2) \\
             &amp;=
\frac{1}{n}\sum^{n}_{i=1}(\pmb{a}_i^T\pmb{x}_i-\pmb{a}_i^T\pmb{\overline{x}})^2
\\
             &amp;=
\frac{1}{n}\sum^{n}_{i=1}\pmb{a}_1^T(\pmb{x}_i-\pmb{\overline{x}})\pmb{a}_1^T(\pmb{x}_i-\pmb{\overline{x}})
\\
             &amp;=
\frac{1}{n}\sum^{n}_{i=1}\pmb{a}_1^T(\pmb{x}_i-\pmb{\overline{x}})(\pmb{x}_i-\pmb{\overline{x}})^T\pmb{a}_1
\\
             &amp;= \pmb{a}_1^TS\pmb{a}_1
\end{aligned}
\]</span> 其中<span class="math inline">\(S =
\frac{1}{n}\sum^{n}_{i=1}(\pmb{x}_i-\pmb{\overline{x}})(\pmb{x}_i-\pmb{\overline{x}})^T\)</span>
是<font color="orange">协方差矩阵</font></p>
<p>问题简化为如下: <span class="math display">\[
\underset{\pmb{a}_1}{max}\pmb{a}_1^T S \pmb{a}_1
\]</span></p>
<p><span class="math display">\[
\textcolor{red}{s.t. \; \; \pmb{a}_1^T \pmb{a}_1 = 1}
\]</span></p>
<p>令<span class="math inline">\(\lambda\)</span>为拉格朗日乘数 <span class="math display">\[
L = \pmb{a}_1^T S \pmb{a}_1 - \lambda(\textcolor{orange}{\pmb{a}_1^T
\pmb{a}_1 - 1})
\]</span></p>
<p><span class="math display">\[
\frac{\partial L}{\partial \pmb{a}_1} = 2S\pmb{a}_1 - 2\lambda \pmb{a}_1
= 0
\]</span></p>
<p><span class="math display">\[
S\pmb{a}_1 = \lambda \pmb{a}_1
\]</span></p>
<p>于是<span class="math inline">\(\pmb{a}_1\)</span>是<span class="math inline">\(S\)</span>对应的<font color="red">最大</font>特征值<span class="math inline">\(\lambda = \lambda_1\)</span>的特征向量</p>
<p><span class="math inline">\(z^{(2)}\)</span>同<span class="math inline">\(z^{(1)}\)</span>独立，故协方差为0 <span class="math display">\[
\underset{\pmb{a}_2}{max}\pmb{a}_2^T S \pmb{a}_2 \\
s.t. \; \; \pmb{a}_2^T \pmb{a}_2 = 1, \;
\textcolor{red}{cov(z^{(2)},z^{(1)}) = 0}
\]</span></p>
<p><span class="math display">\[
cov(z^{(2)},z^{(1)}) = \pmb{a}_2^T S \pmb{a}_1 = \lambda \pmb{a}_2^T
\pmb{a}_1 = 0
\]</span></p>
<p><span class="math display">\[
S \pmb{a}_2 = \lambda \pmb{a}_2
\]</span></p>
<p>于是<span class="math inline">\(\pmb{a}_2\)</span>是<span class="math inline">\(S\)</span>对应<font color="red">第二大</font>特征值<span class="math inline">\(\lambda = \lambda_2\)</span>的特征向量</p>
<p>以此类推 <span class="math display">\[
var(z^{(k)}) = \pmb{a}_k^T S \pmb{a}_k = \lambda_k
\]</span></p>
<p>于是计算主成分(PC)的步骤如下：</p>
<ul>
<li>得到协方差矩阵<span class="math inline">\(S\)</span></li>
<li>计算其特征向量<span class="math inline">\(\{\pmb{a}_i\}^p_{i=1}\)</span></li>
<li>使用最大的<span class="math inline">\(d\)</span>个特征向量<span class="math inline">\(\{\pmb{a}_i\}^d_{i=1}\)</span>得到主成分</li>
<li>变换矩阵<span class="math inline">\(A\)</span>为<span class="math inline">\(A = [\pmb{a}_1,...,\pmb{a}_d]\)</span></li>
</ul>
<p>PCA在图像压缩上的应用</p>
<figure>
<img src="/2022/10/12/%E9%99%8D%E7%BB%B4/1.png" alt="1">
<figcaption aria-hidden="true">1</figcaption>
</figure>
<h2 id="线性判别分析lda">7.线性判别分析(LDA)</h2>
<p>在降维的同时尽可能保留更多维度的信息</p>
<p>找到不同类别最佳分开的方向</p>
<p>尽可能多地考虑类内分布以及类间分散</p>
<p><font color="red">让投影降维后类内方差尽可能小，类间方差尽可能大</font></p>
<p>给定两类<span class="math inline">\(\omega_1 , \omega_2\)</span></p>
<p>定义 <span class="math display">\[
\pmb{\mu}_i = \frac{1}{n_i}\sum_{x \in \omega_i} \pmb{x}
\]</span> 可以理解为变换前的中心位置</p>
<p>定义 <span class="math display">\[
\tilde{\mu}_i = \frac{1}{n_i}\sum_{z\in\omega_i}z
\]</span> 可以理解为投影后第<span class="math inline">\(i\)</span>类的中心点位置</p>
<p>定义 <span class="math display">\[
\tilde{s}^2_i = \sum_{z \in \omega_i}(z - \tilde{\mu}_i)^2
\]</span> 可以理解为类内方差</p>
<p>于是可以定义一个函数 <span class="math display">\[
J(\pmb{a}) = \frac{(\tilde{\mu}_1-\tilde{\mu}_2)^2}{\tilde{s}^2_1 +
\tilde{s}^2_2}
\]</span>
优化的目标便是<font color="red">最大化此函数</font>(类内方差尽可能小，类间方差尽可能大)</p>
<p>类内散度矩阵<span class="math inline">\(S_W\)</span> <span class="math display">\[
S_W = (\pmb{x}-\pmb{\mu}_i)(\pmb{x}-\pmb{\mu}_i)^T
\]</span> 类间散度矩阵<span class="math inline">\(S_B\)</span> <span class="math display">\[
S_B = (\pmb{\mu}_1-\pmb{\mu}_2)(\pmb{\mu}_1-\pmb{\mu}_2)^T
\]</span></p>
<p>于是有 <span class="math display">\[
J(\pmb{a}) = \frac{\pmb{a}^T S_B \pmb{a}}{\pmb{a}^T S_W \pmb{a}}
\]</span> 其中 <span class="math display">\[
S_B \pmb{a} = \lambda S_W \pmb{a}
\]</span> 利用<span class="math inline">\(S_B \pmb{a} = \lambda
(\pmb{\mu}_1 - \pmb{\mu}_2)\)</span>解得 <span class="math display">\[
\pmb{a}^* = S_W^{-1}(\pmb{\mu}_1 - \pmb{\mu}_2)
\]</span></p>
<p>多类情形下： <span class="math display">\[
S_T = S_W + S_B
\]</span></p>
<p><span class="math display">\[
J(\pmb{a}) = \frac{\pmb{a}^T S_W \pmb{a}}{\pmb{a}^T S_T \pmb{a}}
\]</span></p>
<p><span class="math display">\[
S_B \pmb{a} = \lambda S_T \pmb{a}
\]</span></p>
<p>主要的步骤：</p>
<ul>
<li>找到散度矩阵<span class="math inline">\(S_B\)</span>和<span class="math inline">\(S_W\)</span></li>
<li>利用<span class="math inline">\(S_B \pmb{a} = \lambda S_W
\pmb{a}\)</span> 或<span class="math inline">\(S_B \pmb{a} = \lambda S_T
\pmb{a}\)</span>计算特征向量<span class="math inline">\(\{\pmb{a}_i\}^{c-1}_{i=1}\)</span>,其中c为类别的数量</li>
<li>变换矩阵<span class="math inline">\(A\)</span> 为<span class="math inline">\(A = [\pmb{a}_1,...,\pmb{a}_{c-1}]\)</span></li>
</ul>
<h2 id="局部保留投影lpp">8.局部保留投影(LPP)</h2>
<p>定义矩阵<span class="math inline">\(W \in \mathcal{R}^{n \times
n}\)</span> <span class="math display">\[
w_{ij}=
\begin{cases}
1&amp; \text{第i个向量和第j个向量相邻}\\
0&amp; \text{其它情况}
\end{cases}
\]</span></p>
<p>目标： <span class="math display">\[
\begin{aligned}
min\sum_{ij}w_{ij}(z_i - z_j)^2 &amp;=
min\sum_{ij}w_{ij}(\pmb{a}^T\pmb{x}_i - \pmb{a}^T\pmb{x}_j)^2 \\
&amp;= min\sum_{ij}w_{ij}\pmb{a}^T(\pmb{x}_i - \pmb{x}_j)(\pmb{x}_i -
\pmb{x}_j)^T\pmb{a} \\
&amp;=min\pmb{a}^T\sum_{ij}w_{ij}(\pmb{x}_i\pmb{x}_i^T -
\pmb{x}_i\pmb{x}_j^T-\pmb{x}_j\pmb{x}_i^T + \pmb{x}_j\pmb{x}_j^T)\pmb{a}
\\
&amp;=min(\pmb{a}^T\sum_{ij}w_{ij}(-
\pmb{x}_i\pmb{x}_j^T-\pmb{x}_j\pmb{x}_i^T)\pmb{a} +
\pmb{a}^T\sum_{ij}w_{ij}(\pmb{x}_i\pmb{x}_i^T +
\pmb{x}_j\pmb{x}_j^T)\pmb{a} ) \\
&amp;= min \pmb{a}^T((-2XWX^T)+(2XDW^T)) \pmb{a} \\
&amp;= min 2\pmb{a}^T(-W + D) \pmb{a} \\
&amp;= min 2\pmb{a}^T L \pmb{a}
\end{aligned}
\]</span> 其中<span class="math inline">\(D = \begin{bmatrix} d_{11}
&amp; \cdots &amp; 0 \\ \vdots
&amp;\ddots&amp;\vdots\\0&amp;\cdots&amp;d_{nn} \end{bmatrix}\)</span>,
<span class="math inline">\(d_{ii} = \sum_j w_{ij}\)</span></p>
<p><span class="math display">\[
min \frac{\pmb{a}^T XWX^T \pmb{a}}{\pmb{a}^T XDX^T \pmb{a}}
\]</span></p>
<p><span class="math display">\[
\pmb{a}^T XWX^T \pmb{a} = \lambda \pmb{a}^T XDX^T \pmb{a}
\]</span></p>
]]></content>
      <categories>
        <category>机器学习</category>
      </categories>
      <tags>
        <tag>机器学习</tag>
      </tags>
  </entry>
  <entry>
    <title>贝叶斯决策理论</title>
    <url>/2022/09/13/%E8%B4%9D%E5%8F%B6%E6%96%AF%E5%86%B3%E7%AD%96%E7%90%86%E8%AE%BA/</url>
    <content><![CDATA[<style>
  .markdown-body {
    font-family: Microsoft JhengHei, SimHei;
    font-size: 16px;
  }
</style>
<h1 align="center">
贝叶斯决策理论
</h1>
<h2 id="basics-of-probability概率论基础知识">1. Basics of
Probability(概率论基础知识)</h2>
<ul>
<li>$ A独立于B时,P(A|B) = P(A) $</li>
<li>$ P(A|B)= $</li>
<li>$ A、B相互独立 当且仅当 P(A,B)=P(A)P(B) $</li>
</ul>
<h2 id="bayes-theorem贝叶斯理论">2. Bayes' Theorem(贝叶斯理论)</h2>
<p><span class="math display">\[
P(\omega|x) = \frac{p(x|\omega)p(\omega)}{p(x)}\\
Posterior = (Likelihood \times Prior) / Evidence\\
p(x) = \sum_{i=1}^{k}p(x|\omega_i)p(\omega_i)
\]</span></p>
<ul>
<li><span class="math inline">\(P(\omega|x)\)</span> :
posterior,后验概率,<font color="red">已发生事件</font>出于某种因素引发的概率</li>
<li><span class="math inline">\(p(x|\omega)\)</span> :
likelihood,似然,数据符合<font color="red">某种分布</font>的概率大小</li>
<li><span class="math inline">\(p(\omega)\)</span> :
prior,先验概率,<font color="red">未发生事件</font>依据以往经验得知的概率</li>
<li><span class="math inline">\(p(x)\)</span> :
evidence,往往作为一个<font color="red">常数</font></li>
</ul>
<blockquote>
<p>其中 x为样本</p>
</blockquote>
<h2 id="optimal-bayes-decision-rule最优贝叶斯决策规则">3. Optimal Bayes
Decision Rule(最优贝叶斯决策规则)</h2>
<p><strong>一个物体选择后验概率大的作为其分类可以最小化决策误差</strong></p>
<p><span class="math inline">\(P(\omega_1|x) &gt;
P(\omega_2|x)\)</span>时认为它是<span class="math inline">\(\omega_1\)</span></p>
<p><span class="math inline">\(P(\omega_1|x) &lt;
P(\omega_2|x)\)</span>时认为它是<span class="math inline">\(\omega_2\)</span></p>
<blockquote>
<p>同理或者选择风险R小的</p>
</blockquote>
<p>特殊情况：</p>
<ul>
<li><p><span class="math inline">\(p(\omega_1)=p(\omega_2)\)</span> :
<span class="math inline">\(p(x|\omega_1)&gt;p(x|\omega_2)\)</span>时认为是<span class="math inline">\({\omega}_1\)</span></p>
<blockquote>
<p>最大似然决策法</p>
<p>本质上和一般情况没有区别，只是先验概率相同可以同时约去，不加入比较，直接比较似然度</p>
</blockquote></li>
<li><p><span class="math inline">\(p(x|\omega_1)=p(x|\omega_2)\)</span>
: <span class="math inline">\(p(\omega_1)&gt;p(\omega_2)\)</span>时认为是<span class="math inline">\({\omega}_1\)</span></p>
<blockquote>
<p>同上</p>
</blockquote></li>
</ul>
<h2 id="bayes-risk">4. Bayes Risk</h2>
<p>Conditional Risk <span class="math display">\[
R(\alpha_i|x)=\sum_{j=1}^{c}\lambda(\alpha_i|\omega_j)P(\omega_j|x)
\]</span></p>
<blockquote>
<p><span class="math inline">\(\alpha\)</span> 代表 采取的行为</p>
</blockquote>
<p>Overall Risk <span class="math display">\[
R = \int R(\alpha_i|x)p(x)dx
\]</span> Bayes Risk</p>
<ul>
<li>风险最小时的R</li>
</ul>
<h2 id="example-1two-category-classification">Example 1：Two-category
classification</h2>
<p>给定： <span class="math display">\[
\alpha_1 = deciding \space \omega_1 \\
\alpha_2 = deciding \space \omega_2 \\
\lambda_{ij} = \lambda(\alpha_i | \omega_j)
\]</span> 于是条件风险： <span class="math display">\[
R(\alpha_1 | x) = \lambda_{11}P(\omega_1 | x) + \lambda_{12}P(\omega_2 |
x) \\
R(\alpha_2 | x) = \lambda_{21}P(\omega_1 | x) + \lambda_{22}P(\omega_2 |
x)
\]</span> 如何找到贝叶斯风险？？？</p>
<p>认为是<span class="math inline">\({\omega}_1\)</span>当 <span class="math display">\[
R(\alpha_1 | x) &lt; R(\alpha_2 | x)
\]</span> 展开并移项化简得到(认为是<span class="math inline">\({\omega}_1\)</span>的情况) <span class="math display">\[
\frac{P(x|\omega_1)}{P(x|\omega_2)} &gt;
\frac{\lambda_{12}-\lambda_{22}}{\lambda_{21}-\lambda_{11}} \times
\frac{P(\omega_2)}{P(\omega_1)}
\]</span></p>
<h2 id="example-2-minimum-error-rate-classification">Example 2:
Minimum-Error-Rate Classification</h2>
<p>给定</p>
<ul>
<li>对于动作<span class="math inline">\(\alpha_i\)</span>和事实上的类别<span class="math inline">\(\omega_j\)</span> ,如果<span class="math inline">\(i=j\)</span>就是正确的，否则错误</li>
</ul>
<p>找到最小损失的分类</p>
<p>写出损失函数(Zero-one loss function): <span class="math display">\[
\lambda(\alpha_i | \omega_j) =
\begin{cases}
0&amp; \text{i = j}\\
1&amp; \text{i} \neq \text{j}
\end{cases}
\]</span> 于是可以计算条件风险 <span class="math display">\[
R(\alpha_i|x) = \sum_{j=1}^{c} \lambda(\alpha_i|\omega_j)P(\omega_j | x)
\\
= \sum_{j{\neq}i} P(\omega_j | x) = 1-P(\omega_i | x)
\]</span>
需要风险最小化，由上述式子可知需要后验概率最大化，选择后验概率最大的即可</p>
]]></content>
      <categories>
        <category>机器学习</category>
      </categories>
      <tags>
        <tag>机器学习</tag>
      </tags>
  </entry>
</search>
